# Documentaci√≥n T√©cnica - Sistema de Monitoreo y Advisor de Sorters

**Proyecto:** MonitoreoDanich  
**Prop√≥sito:** Sistema completo de monitoreo continuo, recolecci√≥n de datos, inferencia autom√°tica de decisiones y asesoramiento inteligente con IA para optimizaci√≥n de sorters de fruta  
**Fecha:** Noviembre 2025  
**Versi√≥n:** 2.0  
**Lenguajes:** Go 1.25.4 + Python 3.11

---

## üìë Tabla de Contenidos

1. [Visi√≥n General del Sistema](#visi√≥n-general-del-sistema)
2. [Arquitectura General](#arquitectura-general)
3. [Stack Tecnol√≥gico](#stack-tecnol√≥gico)
4. [Sistema de Monitoreo](#sistema-de-monitoreo)
5. [Sistema de Advisor (IA)](#sistema-de-advisor-ia)
6. [Sistema de Inferencia Autom√°tica](#sistema-de-inferencia-autom√°tica)
7. [Machine Learning y Entrenamiento](#machine-learning-y-entrenamiento)
8. [Modelos de Datos](#modelos-de-datos)
9. [Configuraci√≥n y Despliegue](#configuraci√≥n-y-despliegue)
10. [Comandos y Herramientas](#comandos-y-herramientas)
11. [Datos Generados y Persistencia](#datos-generados-y-persistencia)
12. [Gu√≠a de Uso y Workflows](#gu√≠a-de-uso-y-workflows)

---

## üéØ Visi√≥n General del Sistema

### ¬øQu√© hace este sistema?

MonitoreoDanich es una **plataforma completa de optimizaci√≥n inteligente** para sorters de fruta que combina:

1. **Monitoreo continuo** de sorters en tiempo real (cada 30 segundos)
2. **Recolecci√≥n autom√°tica** de porcentajes reales desde gr√°ficos HTML/JavaScript
3. **Inferencia autom√°tica** de decisiones a partir de cambios hist√≥ricos
4. **Asesoramiento con IA** mediante LLM (Ollama) para balanceo de sorters
5. **Machine Learning** para predecir razones de decisiones operativas

### Dos Enfoques de IA

El sistema implementa **dos estrategias complementarias** de inteligencia artificial:

#### 1. **Prompting con LLM (Ollama)** - "Don Sergio Virtual"
- **Qu√© hace:** Analiza el estado actual y sugiere movimientos de SKUs entre sorters
- **C√≥mo funciona:** Usa un modelo de lenguaje (phi3:mini o llama3.2:3b) con prompt engineering
- **Ventaja:** No requiere datos hist√≥ricos, funciona desde el d√≠a 1
- **Uso:** Consulta en tiempo real cuando necesitas asesoramiento

#### 2. **Fine-tuning con XGBoost** - "Aprendizaje del pasado"
- **Qu√© hace:** Aprende patrones de decisiones hist√≥ricas y predice razones de cambios
- **C√≥mo funciona:** Entrena un modelo supervisado con decisiones inferidas autom√°ticamente
- **Ventaja:** Detecta patrones que no son obvios, mejora con m√°s datos
- **Uso:** An√°lisis predictivo de qu√© tipo de desbalance caus√≥ una decisi√≥n

### Flujo Completo del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MONITOREO      ‚îÇ  Captura estado cada 30s
‚îÇ   (monitor cmd)  ‚îÇ  - API assignments
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  - Gr√°ficos HTML
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PERSISTENCIA    ‚îÇ  Guarda snapshots + changes
‚îÇ  (dataset.json)  ‚îÇ  - Estado completo
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  - Historial de cambios
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INFERENCIA     ‚îÇ  Analiza cambios hist√≥ricos
‚îÇ  (infer cmd)     ‚îÇ  - Detecta movimientos de SKUs
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  - Infiere razones autom√°ticamente
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                     ‚îÇ
         ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PROMPTING      ‚îÇ  ‚îÇ  FINE-TUNING     ‚îÇ
‚îÇ  (Ollama LLM)    ‚îÇ  ‚îÇ  (train_model)   ‚îÇ
‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ
‚îÇ "¬øQu√© debo       ‚îÇ  ‚îÇ "¬øPor qu√© se     ‚îÇ
‚îÇ  hacer ahora?"   ‚îÇ  ‚îÇ  tom√≥ esta       ‚îÇ
‚îÇ                  ‚îÇ  ‚îÇ  decisi√≥n?"      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üèóÔ∏è Arquitectura General

### Patr√≥n de Dise√±o
**Hexagonal Architecture + Event-Driven Design + AI-Assisted Decision Making + Modular Components**

### Arquitectura Modular (Diciembre 2024)

El sistema ha sido refactorizado de un monolito de **800+ l√≠neas** a una arquitectura modular con **9 componentes especializados**:

#### Beneficios de la Modularizaci√≥n
- ‚úÖ **Mantenibilidad:** Cada archivo tiene una responsabilidad √∫nica (SRP)
- ‚úÖ **Testabilidad:** Componentes aislados f√°ciles de probar
- ‚úÖ **Legibilidad:** Archivos peque√±os (1-5KB) vs monolito (24KB)
- ‚úÖ **Escalabilidad:** Agregar features sin tocar c√≥digo existente
- ‚úÖ **Reutilizaci√≥n:** Componentes independientes reutilizables

#### Estructura Modular

```
pkg/monitor/
‚îú‚îÄ‚îÄ monitor.go       (5.3KB)  ‚Üí Orquestador principal con DI
‚îú‚îÄ‚îÄ models.go        (2.6KB)  ‚Üí Estructuras de datos compartidas
‚îú‚îÄ‚îÄ config.go        (3.3KB)  ‚Üí Carga y parseo de config.yaml
‚îú‚îÄ‚îÄ fetcher.go       (1.1KB)  ‚Üí Cliente HTTP para API
‚îú‚îÄ‚îÄ snapshot.go      (4.5KB)  ‚Üí Construcci√≥n de snapshots
‚îú‚îÄ‚îÄ changes.go       (2.9KB)  ‚Üí Detecci√≥n y an√°lisis de cambios
‚îú‚îÄ‚îÄ persistence.go   (3.4KB)  ‚Üí I/O de archivos JSON
‚îú‚îÄ‚îÄ exporter.go      (3.8KB)  ‚Üí Exportaci√≥n a CSV para ML
‚îî‚îÄ‚îÄ display.go       (3.4KB)  ‚Üí Visualizaci√≥n en consola

Total: 30.3KB en 9 archivos (vs 24KB en 1 archivo monol√≠tico)
```

#### Flujo de Datos Entre M√≥dulos

```
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  monitor.go  ‚îÇ  ‚Üê Punto de entrada, orquesta todo
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ‚Üí config.go       ‚Üí Carga configuraci√≥n
            ‚îú‚îÄ‚Üí fetcher.go      ‚Üí Obtiene assignments (API)
            ‚îú‚îÄ‚Üí snapshot.go     ‚Üí Crea snapshot (+ scraper)
            ‚îú‚îÄ‚Üí changes.go      ‚Üí Detecta diferencias
            ‚îú‚îÄ‚Üí persistence.go  ‚Üí Guarda datos (JSON)
            ‚îú‚îÄ‚Üí exporter.go     ‚Üí Exporta a CSV
            ‚îî‚îÄ‚Üí display.go      ‚Üí Muestra en consola
```

#### Inyecci√≥n de Dependencias

```go
// Constructor con DI
m := &Monitor{
    config:         LoadConfig(),              // config.go
    fetcher:        NewFetcher(url),           // fetcher.go
    persistence:    NewPersistence(config),    // persistence.go
    changeDetector: NewChangeDetector(),       // changes.go
    snapshotBuilder: NewSnapshotBuilder(scraper), // snapshot.go
    exporter:       NewExporter(folder),       // exporter.go
    display:        NewDisplay(config),        // display.go
}
```

**Ventaja:** Cada componente recibe solo lo que necesita, sin acoplamiento global.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      APLICACIONES (cmd/)                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   monitor    ‚îÇ  ‚îÇ capture-charts‚îÇ  ‚îÇ infer-decisions    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   (loop)     ‚îÇ  ‚îÇ   (testing)   ‚îÇ  ‚îÇ  (inference)       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                    ‚îÇ                     ‚îÇ
         ‚ñº                    ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   L√ìGICA DE NEGOCIO (pkg/)                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  monitor/ (ARQUITECTURA MODULAR - 9 componentes)  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ monitor.go ‚Üí Orquestador (DI + Run loop) ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ models.go ‚Üí Estructuras de datos         ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ config.go ‚Üí Carga YAML                   ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ fetcher.go ‚Üí Cliente HTTP API            ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ snapshot.go ‚Üí Construcci√≥n snapshots     ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ changes.go ‚Üí Detecci√≥n de cambios        ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ persistence.go ‚Üí I/O JSON                ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ exporter.go ‚Üí Exportaci√≥n CSV            ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ display.go ‚Üí Visualizaci√≥n consola       ‚îÇ    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  scraper/chart_scraper.go                          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - ScrapeAssignment()  (chromedp un sorter)        ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - ScrapeBothSorters() (ambos sorters)             ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  advisor/advisor.go (IA - Prompting)               ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - GetAdvice()     (consulta Ollama LLM)           ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  advisor/decision_inference.go (ML - Training)     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - InferDecisionsFromChanges() (an√°lisis hist√≥rico)‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - analyzeChange()    (detecta movimientos SKU)    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - inferReason()      (clasifica tipo cambio)      ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - calculateConfidence() (score 0-1)               ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                      ‚îÇ                ‚îÇ
         ‚ñº                      ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       INFRAESTRUCTURA                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  HTTP API    ‚îÇ  ‚îÇ  Chromedp    ‚îÇ  ‚îÇ  Ollama (LLM)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 192.168.*    ‚îÇ  ‚îÇ  (Browser)   ‚îÇ  ‚îÇ  localhost:11434   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  Filesystem (JSON + CSV)                             ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - dataset.json        (snapshots hist√≥ricos)        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - changes_log.json    (cambios detectados)          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - training_data.csv   (dataset ML)                  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - decisiones_inferidas.json (decisions auto)        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - decisiones_training.csv   (para XGBoost)          ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CAPA DE MACHINE LEARNING                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  train_model.py (Python 3.11)                      ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - XGBoost Classifier                              ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - 18 features (base + derived)                    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - 6 clases de decisi√≥n                            ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - One-hot encoding para calibres                  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  - Output: decision_model.pkl                      ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Principios Aplicados

1. **Separation of Concerns**: Cada paquete tiene una responsabilidad √∫nica
2. **Dependency Injection**: ChartScraper se inyecta, sin dependencias c√≠clicas
3. **Single Responsibility**: Funciones peque√±as y enfocadas
4. **Data Persistence**: Estado completo guardado para an√°lisis retrospectivo
5. **No Cyclic Dependencies**: Advisor usa tipos locales, no importa monitor
6. **AI-First Design**: Dos estrategias de IA complementarias (prompting + fine-tuning)

---

## üíª Stack Tecnol√≥gico

### Backend - Go 1.25.4

**¬øPor qu√© Go?**
- ‚úÖ Concurrencia nativa (goroutines) para scraping paralelo
- ‚úÖ Binarios compilados portables sin dependencias externas
- ‚úÖ Alto rendimiento para operaciones de red
- ‚úÖ Excelente para herramientas CLI y daemons

### Machine Learning - Python 3.11

**¬øPor qu√© Python?**
- ‚úÖ Ecosistema ML completo (scikit-learn, XGBoost)
- ‚úÖ Pandas para manipulaci√≥n de datos
- ‚úÖ Integraci√≥n directa con el pipeline de Go (CSV/JSON)
- ‚úÖ Comunidad y bibliotecas maduras

### Librer√≠as Go

#### 1. **chromedp** v0.14.2
```go
import "github.com/chromedp/chromedp"
```
**Prop√≥sito:** Control headless de Chrome para scraping de JavaScript  
**Uso en el proyecto:**
- Navegar a p√°ginas HTML din√°micas (React/Vue)
- Ejecutar JavaScript y esperar renderizado
- Extraer porcentajes desde el DOM final

**Ejemplo clave:**
```go
chromedp.Run(ctx,
    chromedp.Navigate(url),
    chromedp.Sleep(3*time.Second), // Esperar renderizado
    chromedp.Evaluate(`
        (() => {
          const containers = document.querySelectorAll('.percentage-container');
          return Array.from(containers).map(c => [
            c.querySelector('h1:nth-child(1)').textContent, // SKU
            c.querySelector('h1:nth-child(2)').textContent  // Porcentaje
          ]);
        })()
    `, &resultado),
)
```

#### 2. **goquery** v1.11.0
```go
import "github.com/PuerkitoBio/goquery"
```
**Prop√≥sito:** Parsear y consultar documentos HTML (sintaxis jQuery)  
**Uso:** An√°lisis de estructura HTML est√°tico (si fuera necesario)

#### 3. **yaml.v3**
```go
import "gopkg.in/yaml.v3"
```
**Prop√≥sito:** Configuraci√≥n flexible del sistema  
**Uso:** Cargar `config.yaml` para adaptarse a diferentes packings sin recompilar

#### 4. **Librer√≠a Est√°ndar de Go**
```go
"encoding/json"    // Serializaci√≥n JSON (persistencia)
"encoding/csv"     // Exportaci√≥n CSV para ML
"net/http"         // Cliente HTTP (API + Ollama)
"time"             // Manejo de timestamps
"io/ioutil"        // I/O de archivos
"context"          // Timeouts y cancelaci√≥n
"sort"             // Ordenamiento de datos
"strings"          // Normalizaci√≥n de SKUs
"math"             // C√°lculos de confianza
```

### Librer√≠as Python

#### 1. **pandas** 2.3.3
```python
import pandas as pd
```
**Prop√≥sito:** Manipulaci√≥n y limpieza de datasets  
**Uso:**
- Cargar CSV semicolon-separated
- Feature engineering (derived features)
- Manejo de datos faltantes

#### 2. **scikit-learn** 1.7.2
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
```
**Prop√≥sito:** Pipeline de ML cl√°sico  
**Uso:**
- Train/test split
- One-hot encoding de calibres
- M√©tricas de evaluaci√≥n

#### 3. **XGBoost** 3.1.2
```python
from xgboost import XGBClassifier
```
**Prop√≥sito:** Modelo de clasificaci√≥n con gradient boosting  
**Uso:**
- Clasificar tipo de decisi√≥n (6 clases)
- Predecir raz√≥n del movimiento de SKUs
- Feature importance analysis

#### 4. **joblib** 1.5.2
```python
import joblib
```
**Prop√≥sito:** Serializaci√≥n de modelos ML  
**Uso:** Guardar/cargar `decision_model.pkl` y `label_encoder.pkl`

### IA y LLM

#### **Ollama** (Local LLM Server)
```
Modelo usado: phi3:mini (o llama3.2:3b)
Endpoint: http://localhost:11434/api/generate
```
**Prop√≥sito:** Asesoramiento en tiempo real mediante prompting  
**Uso:**
- Analizar estado actual de sorters
- Sugerir movimientos de SKUs
- Responder en formato JSON estructurado

**Ventaja:** No requiere GPU dedicada, corre en CPU local

---

## üì¶ Estructura del Proyecto

```
MonitoreoDanich/
‚îÇ
‚îú‚îÄ‚îÄ cmd/                                 # Puntos de entrada (executables)
‚îÇ   ‚îú‚îÄ‚îÄ monitor/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.go                     # Loop principal de monitoreo (30s)
‚îÇ   ‚îú‚îÄ‚îÄ capture-charts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.go                     # Testing: captura √∫nica
‚îÇ   ‚îú‚îÄ‚îÄ analyze-data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.go                     # An√°lisis de calidad de datos
‚îÇ   ‚îî‚îÄ‚îÄ infer-decisions/
‚îÇ       ‚îî‚îÄ‚îÄ main.go                     # **NUEVO** Inferencia autom√°tica de decisiones
‚îÇ
‚îú‚îÄ‚îÄ pkg/                                 # L√≥gica de negocio
‚îÇ   ‚îú‚îÄ‚îÄ monitor/                        # **MODULARIZADO** - Sistema de monitoreo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor.go                  # Orquestador principal del sistema
‚îÇ   ‚îÇ   ‚îÇ   - Monitor struct            # Coordina todos los componentes
‚îÇ   ‚îÇ   ‚îÇ   - New()                     # Constructor con inyecci√≥n de dependencias
‚îÇ   ‚îÇ   ‚îÇ   - Run()                     # Loop principal
‚îÇ   ‚îÇ   ‚îÇ   - runCycle()                # Un ciclo de monitoreo
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.go                   # Estructuras de datos
‚îÇ   ‚îÇ   ‚îÇ   - Assignment                # Asignaci√≥n SKU ‚Üí Salida
‚îÇ   ‚îÇ   ‚îÇ   - DataSnapshot              # Estado completo del sistema
‚îÇ   ‚îÇ   ‚îÇ   - CalibreDistribution       # Distribuci√≥n de SKUs
‚îÇ   ‚îÇ   ‚îÇ   - TrainingDataset           # Dataset hist√≥rico
‚îÇ   ‚îÇ   ‚îÇ   - ChangeLog                 # Log de cambios
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.go                   # Configuraci√≥n YAML
‚îÇ   ‚îÇ   ‚îÇ   - LoadConfig()              # Carga y parsea config.yaml
‚îÇ   ‚îÇ   ‚îÇ   - SystemConfig struct       # Configuraci√≥n del sistema
‚îÇ   ‚îÇ   ‚îÇ   - PackingConfig, MonitorConfig, DataConfig
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetcher.go                  # Cliente HTTP para API
‚îÇ   ‚îÇ   ‚îÇ   - FetchAssignments()        # GET assignments desde API
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snapshot.go                 # Creaci√≥n de snapshots
‚îÇ   ‚îÇ   ‚îÇ   - SnapshotBuilder           # Constructor de snapshots
‚îÇ   ‚îÇ   ‚îÇ   - CreateSnapshot()          # Genera snapshot completo
‚îÇ   ‚îÇ   ‚îÇ   - captureChartData()        # Integra datos de gr√°ficos
‚îÇ   ‚îÇ   ‚îÇ   - ExtractCalibre()          # Normalizaci√≥n de nombres
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ changes.go                  # Detecci√≥n de cambios
‚îÇ   ‚îÇ   ‚îÇ   - HasChanges()              # Comparaci√≥n r√°pida (bytes)
‚îÇ   ‚îÇ   ‚îÇ   - DetectChanges()           # An√°lisis detallado
‚îÇ   ‚îÇ   ‚îÇ   - DisplayChanges()          # Output consola
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persistence.go              # Persistencia de datos
‚îÇ   ‚îÇ   ‚îÇ   - SaveDataset()             # Guarda dataset.json
‚îÇ   ‚îÇ   ‚îÇ   - LoadOrCreateDataset()     # Carga o inicializa
‚îÇ   ‚îÇ   ‚îÇ   - SaveSnapshot()            # Guarda snapshot actual
‚îÇ   ‚îÇ   ‚îÇ   - LogChange()               # Registra cambios
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exporter.go                 # Exportaci√≥n a CSV
‚îÇ   ‚îÇ   ‚îÇ   - ExportToCSV()             # Genera training_data.csv
‚îÇ   ‚îÇ   ‚îÇ   - createCSVRecord()         # Crea registro por SKU
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ display.go                  # Visualizaci√≥n en consola
‚îÇ   ‚îÇ       - ShowStats()               # Estad√≠sticas del sistema
‚îÇ   ‚îÇ       - ShowAdvice()              # Muestra consejos del advisor
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ scraper/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart_scraper.go            # Scraper de gr√°ficos HTML/JS
‚îÇ   ‚îÇ       - ScrapeAssignment()        # Un sorter
‚îÇ   ‚îÇ       - ScrapeBothSorters()       # Ambos sorters
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ advisor/                        # **NUEVO** Sistema de IA
‚îÇ       ‚îú‚îÄ‚îÄ advisor.go                  # Prompting con Ollama LLM
‚îÇ       ‚îÇ   - GetAdvice()               # Consulta al modelo
‚îÇ       ‚îÇ   - tipos locales (sin dependencias c√≠clicas)
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ decision_inference.go       # Inferencia autom√°tica para ML
‚îÇ           - InferDecisionsFromChanges() # An√°lisis hist√≥rico
‚îÇ           - analyzeChange()           # Detecta movimientos
‚îÇ           - inferReason()             # Clasifica tipo (6 categor√≠as)
‚îÇ           - calculateConfidence()     # Score 0-1
‚îÇ
‚îú‚îÄ‚îÄ training_data/                       # Output: datos generados
‚îÇ   ‚îú‚îÄ‚îÄ dataset.json                    # Snapshots hist√≥ricos completos
‚îÇ   ‚îú‚îÄ‚îÄ current_snapshot.json           # Estado actual (√∫ltimo)
‚îÇ   ‚îú‚îÄ‚îÄ changes_log.json                # Log de cambios detectados
‚îÇ   ‚îú‚îÄ‚îÄ snapshots_YYYYMMDD.json         # Backup diario
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training_data.csv               # **Dataset para ML** (semicolon CSV)
‚îÇ   ‚îÇ   # Columnas: timestamp, sorter_id, sku, calibre, calidad,
‚îÇ   ‚îÇ   #          variedad, lineas, porcentaje, total_skus_activos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ decisiones_inferidas.json       # **NUEVO** Decisiones inferidas
‚îÇ   ‚îÇ   # Con: movimientos, porcentajes antes/despu√©s, raz√≥n, confianza
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ decisiones_training.csv         # **NUEVO** Dataset para XGBoost
‚îÇ       # Columnas: sku, calibre, variedad, de_sorter, a_sorter,
‚îÇ       #          porcentajes antes/despu√©s, impacto, raz√≥n, confianza
‚îÇ
‚îú‚îÄ‚îÄ bin/                                 # Binarios compilados
‚îÇ   ‚îú‚îÄ‚îÄ monitor.exe                     # Monitoreo continuo
‚îÇ   ‚îú‚îÄ‚îÄ capture-charts.exe              # Testing
‚îÇ   ‚îú‚îÄ‚îÄ analyze-data.exe                # An√°lisis de datos
‚îÇ   ‚îî‚îÄ‚îÄ infer-decisions.exe             # **NUEVO** Generar decisiones
‚îÇ
‚îú‚îÄ‚îÄ venv/                                # **NUEVO** Entorno virtual Python
‚îÇ   ‚îú‚îÄ‚îÄ Scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activate                    # Activaci√≥n (bash)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ python.exe                  # Int√©rprete Python 3.11
‚îÇ   ‚îî‚îÄ‚îÄ Lib/                            # Librer√≠as Python
‚îÇ
‚îú‚îÄ‚îÄ train_model.py                       # **NUEVO** Script de entrenamiento ML
‚îÇ   # XGBoost para clasificar tipo de decisi√≥n
‚îÇ   # Input: decisiones_training.csv
‚îÇ   # Output: decision_model.pkl, label_encoder.pkl, training_metrics.json
‚îÇ
‚îú‚îÄ‚îÄ decision_model.pkl                   # **NUEVO** Modelo entrenado (cuando hay datos)
‚îú‚îÄ‚îÄ label_encoder.pkl                    # **NUEVO** Encoder de etiquetas
‚îú‚îÄ‚îÄ training_metrics.json                # **NUEVO** M√©tricas del modelo
‚îÇ
‚îú‚îÄ‚îÄ config.yaml                          # Configuraci√≥n activa
‚îú‚îÄ‚îÄ go.mod                               # Dependencias Go
‚îú‚îÄ‚îÄ go.sum                               # Checksums
‚îÇ
‚îú‚îÄ‚îÄ DOCUMENTACION_TECNICA.md             # Este archivo
‚îú‚îÄ‚îÄ FLUJO_DATOS.md                       # Flujo detallado de datos
‚îú‚îÄ‚îÄ README.md                            # Gu√≠a r√°pida
‚îî‚îÄ‚îÄ todo.md                              # TODOs y mejoras futuras
```

### Archivos Clave por Funci√≥n

#### Monitoreo
- `cmd/monitor/main.go` ‚Üí Punto de entrada
- `pkg/monitor/monitoreo.go` ‚Üí L√≥gica completa
- `pkg/scraper/chart_scraper.go` ‚Üí Captura de gr√°ficos

#### Advisor (IA)
- `pkg/advisor/advisor.go` ‚Üí Prompting con Ollama
- `pkg/advisor/decision_inference.go` ‚Üí Inferencia autom√°tica
- `cmd/infer-decisions/main.go` ‚Üí Generador de dataset

#### Machine Learning
- `train_model.py` ‚Üí Script de entrenamiento
- `decisiones_training.csv` ‚Üí Dataset de entrada
- `decision_model.pkl` ‚Üí Modelo entrenado

#### Configuraci√≥n
- `config.yaml` ‚Üí Configuraci√≥n del sistema
- `.env` ‚Üí Variables de entorno (legacy, opcional)

---

## üîÑ Sistema de Monitoreo

### Ciclo Principal (cada 30 segundos)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. INICIO DEL CICLO                                          ‚îÇ
‚îÇ    - Timestamp actual                                        ‚îÇ
‚îÇ    - Contador de verificaci√≥n                                ‚îÇ
‚îÇ    - Carga config.yaml si cambi√≥                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. OBTENER ASSIGNMENTS (HTTP GET)                            ‚îÇ
‚îÇ    URL: http://192.168.121.2/api/api/assignments_list       ‚îÇ
‚îÇ    Response: []Assignment { Salida, SKU, SorterID }         ‚îÇ
‚îÇ    Ejemplo: [                                                ‚îÇ
‚îÇ      {"salida": 2, "sku": "4J-D-LAPINS-C5WFTFG", "sorter_id": 1}, ‚îÇ
‚îÇ      {"salida": 7, "sku": "4J-D-LAPINS-C5WFTFG", "sorter_id": 1}, ‚îÇ
‚îÇ      ...                                                     ‚îÇ
‚îÇ    ]                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. CAPTURAR GR√ÅFICOS (chromedp)                              ‚îÇ
‚îÇ    Para cada sorter (1 y 2):                                 ‚îÇ
‚îÇ      a) Navegar a: http://192.168.121.2/assignment/{id}     ‚îÇ
‚îÇ      b) Esperar 3s para renderizado JavaScript               ‚îÇ
‚îÇ      c) Ejecutar script para extraer DOM:                    ‚îÇ
‚îÇ         document.querySelectorAll(                           ‚îÇ
‚îÇ           'div.relative.w-full.flex.justify-between...'      ‚îÇ
‚îÇ         )                                                    ‚îÇ
‚îÇ      d) Para cada container:                                 ‚îÇ
‚îÇ         - h1[0] = SKU completo ("4J-D-LAPINS-C5WFTFG")      ‚îÇ
‚îÇ         - h1[1] = Porcentaje ("26%")                        ‚îÇ
‚îÇ      e) Parsear: remover %, convertir a float64             ‚îÇ
‚îÇ    Result: ChartData {                                       ‚îÇ
‚îÇ      SorterID: 1,                                            ‚îÇ
‚îÇ      Percentages: {"4J-D-LAPINS": 26.0, "3J-D-LAPINS": 33.0},‚îÇ
‚îÇ      OrderedSKUs: ["4J-D-LAPINS", "3J-D-LAPINS", ...],      ‚îÇ
‚îÇ      TotalSKUs: 11                                           ‚îÇ
‚îÇ    }                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. CREAR SNAPSHOT (createSnapshot)                           ‚îÇ
‚îÇ    Combinar datos:                                           ‚îÇ
‚îÇ      - Assignments del API (configuraci√≥n)                   ‚îÇ
‚îÇ      - Porcentajes reales del gr√°fico (sensores)            ‚îÇ
‚îÇ    Normalizar SKUs: ToUpper() para matching                  ‚îÇ
‚îÇ    Calcular distribuciones multidimensionales:               ‚îÇ
‚îÇ      - Global: promedio entre sorters                        ‚îÇ
‚îÇ      - Por Sorter: datos de cada sorter                      ‚îÇ
‚îÇ      - Por Salida: mapeando SKU ‚Üí Salida                    ‚îÇ
‚îÇ      - Por Sorter+Salida: combinaci√≥n                        ‚îÇ
‚îÇ    Generar DataSnapshot completo con timestamp               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. DETECTAR CAMBIOS (hasChanges + detectChanges)            ‚îÇ
‚îÇ    Comparar con estado anterior (last_assignments.json):     ‚îÇ
‚îÇ      - Serializar ambos a JSON                               ‚îÇ
‚îÇ      - Comparar bytes (r√°pido)                               ‚îÇ
‚îÇ    SI hay cambios:                                           ‚îÇ
‚îÇ      a) Ejecutar detectChanges() detallado:                  ‚îÇ
‚îÇ         - Crear mapas: key = "SKU-SorterID-Salida"          ‚îÇ
‚îÇ         - Identificar REMOVED (en old, no en new)            ‚îÇ
‚îÇ         - Identificar ADDED (en new, no en old)              ‚îÇ
‚îÇ         - Identificar MODIFIED (mismo key, diff value)       ‚îÇ
‚îÇ      b) Registrar en changes_log.json con:                   ‚îÇ
‚îÇ         - Timestamp                                          ‚îÇ
‚îÇ         - ChangeType: "update" o "initial"                   ‚îÇ
‚îÇ         - Listas: Added, Removed, Modified                   ‚îÇ
‚îÇ         - Description generada                               ‚îÇ
‚îÇ      c) Mostrar en consola: üîî CAMBIOS DETECTADOS           ‚îÇ
‚îÇ    SI NO hay cambios:                                        ‚îÇ
‚îÇ      Mostrar: ‚úì Sin cambios en assignments                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. EXPORTAR A CSV (exportToCSV)                              ‚îÇ
‚îÇ    Para cada sorter con chart_data:                          ‚îÇ
‚îÇ      Para cada SKU con porcentaje:                           ‚îÇ
‚îÇ        a) Parsear SKU:                                       ‚îÇ
‚îÇ           "4J-D-LAPINS-C5WFTFG" ‚Üí                           ‚îÇ
‚îÇ             Calibre: "4J"                                    ‚îÇ
‚îÇ             Calidad: "D"                                     ‚îÇ
‚îÇ             Variedad: "LAPINS"                               ‚îÇ
‚îÇ        b) Obtener l√≠neas con getSalidasForSKU():            ‚îÇ
‚îÇ           - Buscar en assignments del sorter                 ‚îÇ
‚îÇ           - Normalizar (MAY√öSCULAS) para match               ‚îÇ
‚îÇ           - Formatear: "L2 L7"                              ‚îÇ
‚îÇ        c) Escribir fila CSV (semicolon delimiter):           ‚îÇ
‚îÇ           timestamp;sorter_id;sku;calibre;calidad;           ‚îÇ
‚îÇ           variedad;lineas;porcentaje;total_skus_activos      ‚îÇ
‚îÇ    Modo: APPEND (no borra datos anteriores)                 ‚îÇ
‚îÇ    Output: training_data/training_data.csv                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. PERSISTIR DATOS ADICIONALES                               ‚îÇ
‚îÇ    - dataset.json: agregar snapshot al array de snapshots    ‚îÇ
‚îÇ      (historial completo, crece indefinidamente)             ‚îÇ
‚îÇ    - current_snapshot.json: sobrescribir con √∫ltimo estado   ‚îÇ
‚îÇ      (siempre muestra el estado actual)                      ‚îÇ
‚îÇ    - last_assignments.json: actualizar para pr√≥xima comparaci√≥n‚îÇ
‚îÇ    - snapshots_YYYYMMDD.json: backup diario autom√°tico       ‚îÇ
‚îÇ      (se crea uno nuevo cada d√≠a)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. MOSTRAR ESTAD√çSTICAS (displayStats)                       ‚îÇ
‚îÇ    Terminal output:                                          ‚îÇ
‚îÇ      ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó ‚îÇ
‚îÇ      ‚ïë Monitoreo #47 - 2025-11-27 17:08:02               ‚ïë ‚îÇ
‚îÇ      ‚ïë Total snapshots: 47                                ‚ïë ‚îÇ
‚îÇ      ‚ïë Tiempo activo: 23m 30s                            ‚ïë ‚îÇ
‚îÇ      ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£ ‚îÇ
‚îÇ      ‚ïë SORTER 1                                           ‚ïë ‚îÇ
‚îÇ      ‚ïë   4J-D-LAPINS: 26%   L2 L7                        ‚ïë ‚îÇ
‚îÇ      ‚ïë   3J-D-LAPINS: 33%   L5                           ‚ïë ‚îÇ
‚îÇ      ‚ïë   2J-D-LAPINS: 18%   L3 L6                        ‚ïë ‚îÇ
‚îÇ      ‚ïë SORTER 2                                           ‚ïë ‚îÇ
‚îÇ      ‚ïë   4J-D-LAPINS: 25%   L4                           ‚ïë ‚îÇ
‚îÇ      ‚ïë   3J-D-LAPINS: 35%   L1 L2                        ‚ïë ‚îÇ
‚îÇ      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚îÇ
‚îÇ    Pr√≥xima verificaci√≥n en 30s...                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
                   [SLEEP 30s]
                         ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> REPETIR DESDE PASO 1
```

### Funci√≥n Principal: `Run()`

**Archivo:** `pkg/monitor/monitoreo.go`  
**Responsabilidad:** Orquestador completo del sistema

```go
func Run() {
    // 1. Inicializaci√≥n
    loadConfig()                         // Cargar config.yaml
    loadExistingDataset()                // Cargar dataset.json si existe
    chartScraper = scraper.New()         // Inicializar chromedp
    startTime := time.Now()
    checkCount := 0
    
    // 2. Loop infinito
    for {
        checkCount++
        timestamp := time.Now()
        
        // 3. Recolecci√≥n de datos
        assignments := fetchAssignments()  // HTTP GET al API
        snapshot := createSnapshot(timestamp, assignments)
        
        // 4. Detecci√≥n de cambios
        if hasChanges(lastAssignments, assignments) {
            changes := detectChanges(lastAssignments, assignments)
            logChanges(changes)
            showChangeAlert(changes)
        }
        
        // 5. Persistencia
        dataset.Snapshots = append(dataset.Snapshots, snapshot)
        saveDataset()                     // dataset.json
        saveCurrentSnapshot(snapshot)     // current_snapshot.json
        exportToCSV(snapshot)             // training_data.csv
        
        // 6. Display
        displayStats(checkCount, startTime, snapshot)
        
        // 7. Espera
        time.Sleep(checkInterval)  // 30s (configurable en YAML)
    }
}
```

### Funci√≥n: `createSnapshot()`

**Algoritmo completo:**
```
INPUT: timestamp, assignments[]
OUTPUT: DataSnapshot completo

1. Inicializar snapshot base:
   - Timestamp formatado
   - DateTime objeto
   - Assignments copiados
   - Contadores por sorter y salida

2. SI captureCharts == true:
   a) chartDataList = chartScraper.ScrapeBothSorters()
   b) snapshot.ChartData = map[sorter_id] ‚Üí ChartData
   
   c) Calcular calibre_percent (GLOBAL):
      - Inicializar resultado vac√≠o
      - Agregar Sorter 1 percentages
      - SI hay Sorter 2:
        - Para cada SKU en Sorter 2:
          SI SKU ya existe en resultado:
            resultado[SKU] = (s1_percent + s2_percent) / 2.0
          SI NO:
            resultado[SKU] = s2_percent
      - snapshot.CalibrePercent = resultado
   
   d) Para cada sorter con chart_data:
      - Inicializar map vac√≠o para calibre_by_sorter[sorterID]
      - Para cada (sku, percent) en chart.Percentages:
        SI percent > 0:
          calibre_by_sorter[sorterID][sku] = CalibreDistribution{
            Percentage: percent
          }
   
   e) Mapear a SALIDAS:
      - Para cada assignment en sorter espec√≠fico:
        SI assignment.SKU existe en chart.Percentages:
          realPercent = chart.Percentages[assignment.SKU]
          salida = assignment.Salida
          
          SI calibre_by_salida[salida] no existe:
            calibre_by_salida[salida] = map vac√≠o
          
          calibre_by_salida[salida][sku] = CalibreDistribution{
            Percentage: realPercent
          }
   
   f) Mapear a SORTER+SALIDA:
      - key = fmt.Sprintf("%d-%d", sorterID, salida)
      - Similar al paso (e) pero con key combinada

3. RETURN snapshot completo
```

### Funci√≥n: `exportToCSV()`

**Formato del CSV generado:**
```csv
timestamp;sorter_id;sku;calibre;calidad;variedad;lineas;porcentaje;total_skus_activos
2025-11-27 17:08:02;1;4J-D-LAPINS-C5WFTFG;4J;D;LAPINS;L2 L7;26.0;11
2025-11-27 17:08:02;1;3J-D-LAPINS-C5WFTFG;3J;D;LAPINS;L5;33.0;11
```

**Caracter√≠sticas:**
- **Delimitador:** Punto y coma (`;`) para Excel espa√±ol
- **Encoding:** UTF-8
- **Modo:** APPEND (no borra datos anteriores)
- **Crecimiento:** ~15-20 filas por ciclo ‚Üí ~1,800 filas/hora

**Prop√≥sito:** Dataset limpio para entrenar modelos ML que detecten calibres desde im√°genes

---

## ü§ñ Sistema de Advisor (IA)

### Arquitectura del Advisor

El sistema de advisor implementa **dos estrategias complementarias** de inteligencia artificial:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ADVISOR SYSTEM                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                        ‚îÇ
‚îÇ  ESTRATEGIA 1: PROMPTING (advisor.go)                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  LLM (Ollama) con prompt engineering             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Modelo: phi3:mini o llama3.2:3b               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Endpoint: localhost:11434                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Input: Estado actual (DataSnapshot)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Output: Advice JSON estructurado              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Ventaja: Funciona desde el d√≠a 1               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Uso: Asesoramiento en tiempo real               ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  ESTRATEGIA 2: FINE-TUNING (decision_inference.go)    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Inferencia autom√°tica + XGBoost                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Input: changes_log.json + dataset.json       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Proceso: Detecta movimientos autom√°ticamente  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Output: decisiones_training.csv               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Entrenamiento: train_model.py                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Ventaja: Aprende patrones hist√≥ricos            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Uso: Predicci√≥n de razones de decisi√≥n          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Estrategia 1: Prompting con LLM

**Archivo:** `pkg/advisor/advisor.go`

#### Funci√≥n Principal: `GetAdvice()`

```go
func GetAdvice(snapshot DataSnapshot) (*Advice, error)
```

**Entrada:** DataSnapshot con estado actual (assignments + chart_data)  
**Salida:** Advice struct con recomendaci√≥n estructurada

**Proceso:**
```
1. Construir contexto de sorters:
   Para Sorter 1:
     - 4J-D-LAPINS: 26% (l√≠neas L2 L7)
     - 3J-D-LAPINS: 33% (l√≠neas L5)
   Para Sorter 2:
     - 4J-D-LAPINS: 25% (l√≠neas L4)
     - 3J-D-LAPINS: 35% (l√≠neas L1 L2)

2. Generar prompt con template "Don Sergio":
   "Eres Don Sergio, el mejor jefe de packing de Chile con 30 a√±os...
    Reglas sagradas:
    - Nunca dejes diferencia mayor a 8% entre sorters
    - Prioriza mover el SKU con m√°s desbalance
    - Siempre mueve a las l√≠neas del SKU con menos %
    ..."

3. Llamar a Ollama API:
   POST http://localhost:11434/api/generate
   {
     "model": "phi3:mini",
     "prompt": fullPrompt,
     "stream": false,
     "options": {
       "temperature": 0.3,
       "top_p": 0.9
     }
   }

4. Parsear respuesta JSON:
   {
     "accion": "mover" | "no_hacer_nada",
     "sku": "2J-D-LAPINS-C5WFTFG",
     "de_sorter": 1,
     "a_sorter": 2,
     "lineas_sugeridas": "L2 L4 L6",
     "razon": "Explicaci√≥n corta",
     "balance_esperado_despues": "2J-D ‚âà 23% en ambos"
   }

5. Validar y retornar Advice
```

#### Tipo `Advice`

```go
type Advice struct {
    Accion          string  // "mover" o "no_hacer_nada"
    SKU             string  // SKU a mover
    DeSorter        int     // Sorter origen
    ASorter         int     // Sorter destino
    LineasSugeridas string  // "L2 L4 L6"
    Razon           string  // Explicaci√≥n
    BalanceEsperado string  // Estado esperado despu√©s
}
```

#### Tipos Locales (Sin Dependencias C√≠clicas)

**Cr√≠tico:** `advisor.go` define sus propios tipos para evitar importar `monitor`:

```go
// En pkg/advisor/advisor.go
type Assignment struct {
    Salida   int
    SKU      string
    SorterID int
}

type ChartData struct {
    SorterID    int
    Percentages map[string]float64
    OrderedSKUs []string
}

type DataSnapshot struct {
    Assignments []Assignment
    ChartData   map[int]ChartData
}
```

**¬øPor qu√©?** Si `advisor` importara `monitor`, y `monitor` necesitara importar `advisor`, habr√≠a dependencia c√≠clica. Los tipos locales resuelven esto.

#### Prompt Engineering

**Estrategia del prompt:**
1. **Persona definida:** "Don Sergio" - experiencia y autoridad
2. **Reglas claras:** Nunca >8% diferencia, priorizar desbalances
3. **Output estructurado:** JSON estricto sin texto extra
4. **Contexto completo:** Estado actual con l√≠neas f√≠sicas
5. **Temperatura baja:** 0.3 para respuestas m√°s deterministas

**Ejemplo de prompt generado:**
```
Eres Don Sergio, el mejor jefe de packing de Chile con 30 a√±os en sorters de fruta. Hablas directo, claro y con autoridad. Tu misi√≥n es balancear los 2 sorters lo m√°s perfecto posible.

Estado actual (porcentajes reales del gr√°fico):

Sorter 1:
- 4J-D-LAPINS-C5WFTFG: 26% (l√≠neas L2 L7)
- 3J-D-LAPINS-C5WFTFG: 33% (l√≠neas L5)
- 2J-D-LAPINS-C5WFTFG: 18% (l√≠neas L3 L6)

Sorter 2:
- 4J-D-LAPINS-C5WFTFG: 25% (l√≠neas L4)
- 3J-D-LAPINS-C5WFTFG: 35% (l√≠neas L1 L2)
- 2J-D-LAPINS-C5WFTFG: 22% (l√≠neas L5 L7)

Reglas sagradas:
- Nunca dejes diferencia mayor a 8% en la misma variedad entre sorters.
- Prioriza mover el SKU que m√°s desbalance tiene.
- Siempre mueve a las l√≠neas del SKU que tiene menos porcentaje (para no tapar).
- Si est√° casi perfecto (<6% diferencia en todo), di "no_hacer_nada".

Responde EXACTAMENTE en este JSON, sin texto extra:

{
  "accion": "mover" | "no_hacer_nada",
  "sku": "2J-D-LAPINS-C5WFTFG",
  "de_sorter": 1,
  "a_sorter": 2,
  "lineas_sugeridas": "L2 L4 L6",
  "razon": "Explicaci√≥n corta y precisa en espa√±ol",
  "balance_esperado_despues": "2J-D ‚âà 23% en ambos sorters"
}
```

**Respuesta esperada del modelo:**
```json
{
  "accion": "mover",
  "sku": "2J-D-LAPINS-C5WFTFG",
  "de_sorter": 2,
  "a_sorter": 1,
  "lineas_sugeridas": "L3 L6",
  "razon": "2J-D est√° desbalanceado (22% vs 18%). Mover de S2 a S1 para igualar en ~20%.",
  "balance_esperado_despues": "2J-D ‚âà 20% en ambos sorters"
}
```

#### Configuraci√≥n de Ollama

**Instalaci√≥n:**
```bash
# Windows
winget install Ollama.Ollama

# Verificar instalaci√≥n
ollama --version
```

**Descargar modelo:**
```bash
# Opci√≥n 1: Modelo ligero (recomendado para CPU)
ollama pull phi3:mini

# Opci√≥n 2: Modelo m√°s potente (requiere m√°s RAM)
ollama pull llama3.2:3b
```

**Iniciar servidor:**
```bash
ollama serve
# Escucha en http://localhost:11434
```

**Verificar funcionamiento:**
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "phi3:mini",
  "prompt": "Hola",
  "stream": false
}'
```

#### Uso en el Sistema

**Actualmente:** El sistema de prompting est√° **implementado pero no integrado** en el loop principal.

**Para integrarlo en `cmd/monitor/main.go`:**
```go
import "danich/pkg/advisor"

// Despu√©s de createSnapshot()
if checkCount % 10 == 0 {  // Consultar cada 10 ciclos (5 minutos)
    advice, err := advisor.GetAdvice(advisor.DataSnapshot{
        Assignments: snapshot.Assignments,
        ChartData:   convertChartData(snapshot.ChartData),
    })
    
    if err != nil {
        log.Printf("Error obteniendo advice: %v", err)
    } else if advice.Accion == "mover" {
        fmt.Println("\nü§ñ RECOMENDACI√ìN DE DON SERGIO:")
        fmt.Printf("   Mover %s de Sorter %d a Sorter %d\n", 
            advice.SKU, advice.DeSorter, advice.ASorter)
        fmt.Printf("   L√≠neas sugeridas: %s\n", advice.LineasSugeridas)
        fmt.Printf("   Raz√≥n: %s\n", advice.Razon)
        fmt.Printf("   Balance esperado: %s\n", advice.BalanceEsperado)
    }
}
```

---

## üß† Sistema de Inferencia Autom√°tica

### ¬øQu√© problema resuelve?

**Problema:** Para entrenar un modelo ML necesitas datos etiquetados (X ‚Üí y). En nuestro caso:
- **X:** Estado de los sorters (porcentajes, distribuciones)
- **y:** Raz√≥n de la decisi√≥n ("desbalance_severo", "optimizacion_preventiva", etc.)

**Soluci√≥n tradicional:** Una persona revisa cada cambio y etiqueta manualmente.

**Problema:** Imposible en producci√≥n. El sistema genera cambios continuamente y no hay tiempo para etiquetar.

**Soluci√≥n del sistema:** **Inferencia autom√°tica** que analiza cambios hist√≥ricos y deduce la raz√≥n sin intervenci√≥n humana.

### Arquitectura de Inferencia

```
ENTRADA: changes_log.json + dataset.json
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  InferDecisionsFromChanges()            ‚îÇ
‚îÇ  - Lee todos los cambios hist√≥ricos     ‚îÇ
‚îÇ  - Busca snapshot antes/despu√©s         ‚îÇ
‚îÇ  - Analiza movimientos de SKUs          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  analyzeChange()                        ‚îÇ
‚îÇ  - Detecta: ¬øQu√© SKU se movi√≥?         ‚îÇ
‚îÇ  - ¬øDe qu√© sorter a qu√© sorter?         ‚îÇ
‚îÇ  - ¬øQu√© l√≠neas se agregaron/quitaron?  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  inferReason()                          ‚îÇ
‚îÇ  - Calcula diferencia ANTES             ‚îÇ
‚îÇ  - Calcula diferencia DESPU√âS           ‚îÇ
‚îÇ  - Clasifica en 6 categor√≠as:           ‚îÇ
‚îÇ    1. desbalance_severo (>8%)          ‚îÇ
‚îÇ    2. desbalance_moderado (5-8%)       ‚îÇ
‚îÇ    3. sobrecarga_sorter (>80%)         ‚îÇ
‚îÇ    4. optimizacion_preventiva (<5%)     ‚îÇ
‚îÇ    5. redistribucion_calibre           ‚îÇ
‚îÇ    6. ajuste_operacional               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  calculateConfidence()                  ‚îÇ
‚îÇ  - Score 0-1 basado en:                 ‚îÇ
‚îÇ    ‚Ä¢ Datos completos (¬±0.3)            ‚îÇ
‚îÇ    ‚Ä¢ Impacto en balance (¬±0.4)         ‚îÇ
‚îÇ    ‚Ä¢ L√≥gica clara (¬±0.3)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
SALIDA: []InferredDecision
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  decisiones_inferidas.json (detalle)    ‚îÇ
‚îÇ  decisiones_training.csv (para ML)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Archivo: `pkg/advisor/decision_inference.go`

#### Tipo `InferredDecision`

```go
type InferredDecision struct {
    Timestamp string
    SKU       string
    Calibre   string
    Variedad  string
    
    // Movimiento
    DeSorter int
    ASorter  int
    DeLineas string  // "L2 L7"
    ALineas  string  // "L3 L5"
    
    // Estado ANTES del cambio
    PorcentajeAntes_S1 float64
    PorcentajeAntes_S2 float64
    DiferenciaAntes    float64
    TotalSKUsAntes_S1  int
    TotalSKUsAntes_S2  int
    
    // Estado DESPU√âS del cambio
    PorcentajeDespues_S1 float64
    PorcentajeDespues_S2 float64
    DiferenciaDespues    float64
    
    // Inferencia
    RazonInferida  string   // Una de las 6 categor√≠as
    MejoraBalance  bool     // true si diferencia disminuy√≥
    ImpactoBalance float64  // Reducci√≥n de diferencia (positivo = mejora)
    Confianza      float64  // 0-1 (qu√© tan segura es la inferencia)
}
```

#### Funci√≥n Principal: `InferDecisionsFromChanges()`

```go
func InferDecisionsFromChanges(changesPath, snapshotsPath string) ([]InferredDecision, error)
```

**Algoritmo completo:**
```
INPUT: 
  - changes_log.json (cambios detectados)
  - dataset.json (snapshots hist√≥ricos)

OUTPUT:
  - []InferredDecision (decisiones inferidas)

1. Cargar changes_log.json ‚Üí []ChangeEvent
2. Cargar dataset.json ‚Üí []SnapshotData

3. Para cada change en changes:
   
   a) Parsear timestamp del cambio
   
   b) Buscar snapshot ANTES:
      - Recorrer snapshots de atr√°s hacia adelante
      - Encontrar el snapshot cuyo timestamp sea <= changeTime
      - Si no hay, skip este cambio
   
   c) Buscar snapshot DESPU√âS:
      - Recorrer snapshots desde el cambio hacia adelante
      - Encontrar el snapshot cuyo timestamp sea >= changeTime
      - Si no hay, skip este cambio
   
   d) Validar que ambos snapshots tengan chart_data:
      - Si falta data de gr√°ficos, skip (no hay porcentajes)
   
   e) Analizar cambio: movimiento := analyzeChange(snapshotAntes, snapshotDespues, change)
      - Detectar qu√© SKU se movi√≥
      - De qu√© sorter a qu√© sorter
      - Qu√© l√≠neas cambiaron
   
   f) Si se detect√≥ movimiento v√°lido:
      - razon := inferReason(movimiento, snapshotAntes, snapshotDespues)
      - confianza := calculateConfidence(movimiento, razon)
      - Crear InferredDecision con todos los datos
      - Agregar a lista de decisiones

4. RETURN decisiones[]
```

#### Funci√≥n: `analyzeChange()`

**Prop√≥sito:** Detectar qu√© SKU se movi√≥ y hacia d√≥nde

```
INPUT:
  - snapshotAntes
  - snapshotDespues
  - change (Added, Removed, Modified)

OUTPUT:
  - Movimiento detectado o nil

ALGORITMO:

1. Crear mapa de assignments ANTES:
   mapAntes[key] = Assignment
   key = fmt.Sprintf("%d-%s", sorterID, SKU)

2. Crear mapa de assignments DESPU√âS:
   mapDespues[key] = Assignment

3. Buscar cambios significativos:
   
   a) Para cada REMOVED:
      - key_removed = fmt.Sprintf("%d-%s", removed.SorterID, removed.SKU)
      - Buscar si ese SKU aparece en ADDED en otro sorter
      - SI aparece:
        DETECTADO: Movimiento de SKU de sorter X a sorter Y
        Guardar: DeSorter, ASorter, SKU
   
   b) Si no se detect√≥ movimiento claro:
      - Analizar MODIFIED para ver cambios de l√≠neas
      - Si hay cambio de sorter en modified ‚Üí movimiento

4. Obtener porcentajes ANTES y DESPU√âS:
   - PorcentajeAntes_S1 = snapshotAntes.ChartData["1"].Percentages[SKU]
   - PorcentajeAntes_S2 = snapshotAntes.ChartData["2"].Percentages[SKU]
   - Similar para DESPU√âS

5. Obtener l√≠neas ANTES y DESPU√âS:
   - DeLineas = buscar assignments del SKU en DeSorter en snapshotAntes
   - ALineas = buscar assignments del SKU en ASorter en snapshotDespues
   - Formatear como "L2 L7"

6. RETURN estructura con todos los datos del movimiento
```

**Ejemplo de detecci√≥n:**
```
Change:
  Removed: [{"salida": 2, "sku": "4J-D-LAPINS", "sorter_id": 1}]
  Added:   [{"salida": 5, "sku": "4J-D-LAPINS", "sorter_id": 2}]

Detecci√≥n:
  SKU "4J-D-LAPINS" se movi√≥ de Sorter 1 a Sorter 2
  L√≠neas: De "L2" a "L5"
```

#### Funci√≥n: `inferReason()`

**Prop√≥sito:** Clasificar el tipo de decisi√≥n en una de 6 categor√≠as

```go
func inferReason(movimiento Movimiento, snapshotAntes, snapshotDespues SnapshotData) string
```

**Categor√≠as y l√≥gica:**

```
INPUT: Movimiento con porcentajes antes/despu√©s

1. Calcular diferencia ANTES:
   diffAntes = |PorcentajeAntes_S1 - PorcentajeAntes_S2|

2. Calcular diferencia DESPU√âS:
   diffDespues = |PorcentajeDespues_S1 - PorcentajeDespues_S2|

3. Calcular carga total de cada sorter:
   cargaAntes_S1 = suma de todos los porcentajes en Sorter 1
   cargaAntes_S2 = suma de todos los porcentajes en Sorter 2

4. CLASIFICAR:

   SI diffAntes > 8.0:
     RETURN "desbalance_severo"
     Raz√≥n: Diferencia cr√≠tica entre sorters

   SI diffAntes > 5.0 Y diffAntes <= 8.0:
     RETURN "desbalance_moderado"
     Raz√≥n: Diferencia moderada que necesita ajuste

   SI cargaAntes_S1 > 80.0 O cargaAntes_S2 > 80.0:
     RETURN "sobrecarga_sorter"
     Raz√≥n: Un sorter est√° sobrecargado (>80%)

   SI diffAntes < 5.0 Y (diffDespues < diffAntes):
     RETURN "optimizacion_preventiva"
     Raz√≥n: Mejora proactiva aunque diferencia era peque√±a

   SI movimiento involucra cambio de calibre:
     RETURN "redistribucion_calibre"
     Raz√≥n: Rebalanceo de tipos de fruta

   SI NO:
     RETURN "ajuste_operacional"
     Raz√≥n: Cambio por otras razones operativas
```

**Distribuci√≥n t√≠pica de categor√≠as:**
```
desbalance_severo        : 15%
desbalance_moderado      : 35%
sobrecarga_sorter        : 5%
optimizacion_preventiva  : 10%
redistribucion_calibre   : 20%
ajuste_operacional       : 15%
```

#### Funci√≥n: `calculateConfidence()`

**Prop√≥sito:** Asignar un score de confianza (0-1) a la inferencia

```go
func calculateConfidence(movimiento Movimiento, razon string) float64
```

**Algoritmo:**
```
INICIALIZAR: confidence = 0.5 (base)

1. Verificar completitud de datos (+0.3 max):
   SI tiene porcentajes antes Y despu√©s:
     confidence += 0.3
   SI NO:
     confidence += 0.0
     // Inferencia d√©bil sin datos completos

2. Evaluar impacto en balance (+0.4 max):
   impacto = |diffAntes - diffDespues|
   
   SI impacto >= 3.0:  // Cambio significativo
     confidence += 0.4
   SI impacto >= 1.0 Y impacto < 3.0:
     confidence += 0.2
   SI impacto < 1.0:   // Cambio peque√±o
     confidence += 0.1

3. Bonus por razones claras (+0.3):
   SI razon == "desbalance_severo" O "desbalance_moderado":
     confidence += 0.3  // Raz√≥n muy clara
   SI razon == "sobrecarga_sorter":
     confidence += 0.2  // Raz√≥n clara
   SI NO:
     confidence += 0.1  // Raz√≥n inferida

4. Asegurar rango [0, 1]:
   SI confidence > 1.0:
     confidence = 1.0

5. RETURN confidence
```

**Ejemplos de confianza:**
```
Caso 1: Desbalance severo con datos completos
  - Datos completos: +0.3
  - Impacto >3%: +0.4
  - Raz√≥n clara: +0.3
  ‚Üí Confianza: 1.0 (m√°xima)

Caso 2: Optimizaci√≥n preventiva con impacto peque√±o
  - Datos completos: +0.3
  - Impacto 1-3%: +0.2
  - Raz√≥n inferida: +0.1
  ‚Üí Confianza: 0.6 (moderada)

Caso 3: Cambio sin porcentajes despu√©s
  - Datos incompletos: +0.0
  - Impacto desconocido: +0.1
  - Raz√≥n inferida: +0.1
  ‚Üí Confianza: 0.2 (baja)
```

### Comando: `infer-decisions`

**Archivo:** `cmd/infer-decisions/main.go`

**Prop√≥sito:** Ejecutable para generar el dataset de decisiones inferidas

**Uso:**
```bash
./bin/infer-decisions.exe
```

**Proceso:**
```
1. Inicializaci√≥n:
   - Definir rutas:
     changesPath = "training_data/changes_log.json"
     snapshotsPath = "training_data/dataset.json"
     outputJSON = "training_data/decisiones_inferidas.json"
     outputCSV = "training_data/decisiones_training.csv"

2. Inferencia:
   decisions, err := advisor.InferDecisionsFromChanges(changesPath, snapshotsPath)
   SI error:
     log.Fatal(err)

3. Guardar JSON (detallado):
   jsonData, _ := json.MarshalIndent(decisions, "", "  ")
   ioutil.WriteFile(outputJSON, jsonData, 0644)

4. Guardar CSV (para ML):
   file, _ := os.Create(outputCSV)
   writer := csv.NewWriter(file)
   writer.Comma = ';'  // Semicolon para Excel espa√±ol
   
   // Headers
   writer.Write([]string{
     "timestamp", "sku", "calibre", "variedad",
     "de_sorter", "a_sorter", "de_lineas", "a_lineas",
     "porcentaje_antes_s1", "porcentaje_antes_s2", "diferencia_antes",
     "porcentaje_despues_s1", "porcentaje_despues_s2", "diferencia_despues",
     "mejora_balance", "impacto_balance",
     "total_skus_antes_s1", "total_skus_antes_s2",
     "razon_inferida", "confianza"
   })
   
   // Datos
   Para cada decision en decisions:
     writer.Write([...]string{
       decision.Timestamp,
       decision.SKU,
       decision.Calibre,
       ...
       decision.RazonInferida,
       fmt.Sprintf("%.2f", decision.Confianza)
     })
   
   writer.Flush()

5. Estad√≠sticas:
   - Total decisiones generadas
   - Distribuci√≥n por raz√≥n
   - Distribuci√≥n por confianza
   - % que mejoraron balance
   - Impacto promedio en balance
```

**Output ejemplo:**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     INFERENCIA AUTOM√ÅTICA DE DECISIONES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Analizando cambios hist√≥ricos...
‚úì Cargados 12 cambios de changes_log.json
‚úì Cargados 156 snapshots de dataset.json

Procesando...
  Change 1: Detectado movimiento de 4J-D-LAPINS
  Change 2: No se detect√≥ movimiento claro (skip)
  Change 3: Detectado movimiento de 3J-D-LAPINS
  ...

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     RESULTADOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Total decisiones inferidas: 28

Distribuci√≥n por raz√≥n:
  desbalance_moderado      : 12 (43%)
  redistribucion_calibre   : 8 (29%)
  optimizacion_preventiva  : 4 (14%)
  desbalance_severo        : 2 (7%)
  ajuste_operacional       : 2 (7%)

Distribuci√≥n por confianza:
  Alta (>0.7)     : 8 (29%)
  Media (0.5-0.7) : 14 (50%)
  Baja (<0.5)     : 6 (21%)

Balance:
  Mejoraron balance: 7 (25%)
  Mantuvieron: 15 (54%)
  Empeoraron: 6 (21%)

Confianza promedio: 0.42
Impacto promedio: 2.1%

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úì Datos guardados en:
  - training_data/decisiones_inferidas.json (detalle completo)
  - training_data/decisiones_training.csv (para ML)

Listo para entrenar modelo con train_model.py
```

---

## üß© Componentes Principales

### 1. Monitor (`pkg/monitor/monitoreo.go`)

**Responsabilidad:** Orquestar el proceso completo de recolecci√≥n y an√°lisis de datos

#### Funci√≥n Principal: `Run()`
```go
func Run()
```
**Descripci√≥n:** Loop infinito que ejecuta el ciclo de monitoreo  
**Frecuencia:** 30 segundos (configurable)  
**Pasos:**
1. Fetch assignments del API
2. Crear snapshot con an√°lisis
3. Detectar cambios
4. Persistir datos
5. Mostrar estad√≠sticas

#### Funci√≥n: `createSnapshot()`
```go
func createSnapshot(timestamp time.Time, assignments []Assignment) DataSnapshot
```
**Descripci√≥n:** Genera un snapshot completo del estado actual  
**Input:** Timestamp + lista de assignments  
**Output:** DataSnapshot con:
- Contadores b√°sicos (por sorter, por salida)
- Datos de gr√°ficos (si captureCharts=true)
- Distribuciones de calibres multidimensionales

**Algoritmo:**
```
1. Inicializar snapshot con timestamp y assignments
2. Contar assignments por sorter y salida
3. SI captureCharts est√° activo:
   a. Llamar chartScraper.ScrapeBothSorters()
   b. Para cada sorter:
      - Guardar porcentajes reales por SKU
      - Mapear SKUs a salidas usando assignments
      - Calcular distribuci√≥n por sorter+salida
   c. Calcular distribuci√≥n global (promedio)
4. Retornar snapshot completo
```

#### Funci√≥n: `detectChanges()`
```go
func detectChanges(old, new []Assignment) ChangeDetail
```
**Descripci√≥n:** Identifica diferencias entre dos estados  
**Algoritmo:**
```
1. Crear mapas de referencia (SKU+Sorter+Salida como key)
2. Identificar REMOVED (en old pero no en new)
3. Identificar ADDED (en new pero no en old)
4. Identificar MODIFIED (mismo key, diferente valor)
5. Retornar ChangeDetail con listas de cambios
```

#### Funci√≥n: `hasChanges()`
```go
func hasChanges(old, new []Assignment) bool
```
**Descripci√≥n:** Verifica si hay cambios (comparaci√≥n r√°pida)  
**M√©todo:** Serializar ambos a JSON y comparar bytes

---

### 2. ChartScraper (`pkg/scraper/chart_scraper.go`)

**Responsabilidad:** Extraer porcentajes reales desde gr√°ficos HTML

#### Funci√≥n: `ScrapeAssignment()`
```go
func (cs *ChartScraper) ScrapeAssignment(sorterID int) (*ChartData, error)
```
**Descripci√≥n:** Captura datos de un sorter espec√≠fico  
**Proceso:**
```
1. Construir URL: http://192.168.121.2/assignment/{sorterID}
2. Crear contexto de Chrome con timeout (30s)
3. Navegar a la p√°gina
4. Esperar 3 segundos (renderizado JavaScript)
5. Ejecutar script JavaScript:
   - Seleccionar: div.relative.w-full.flex.justify-between.items-center
   - Extraer h1[0] = SKU completo
   - Extraer h1[1] = Porcentaje con %
6. Parsear datos:
   - Remover s√≠mbolo %
   - Convertir string a float64
   - Guardar en map[string]float64
7. Retornar ChartData con orden preservado
```

**JavaScript ejecutado:**
```javascript
(() => {
  const data = [];
  const containers = document.querySelectorAll(
    'div.relative.w-full.flex.justify-between.items-center'
  );
  
  containers.forEach(container => {
    const h1Elements = container.querySelectorAll(
      'h1.text-xs.font-bold.px-1.text-center'
    );
    if (h1Elements.length >= 2) {
      const sku = h1Elements[0].textContent.trim();
      const percentage = h1Elements[1].textContent.trim();
      data.push([sku, percentage]);
    }
  });
  
  return data;
})();
```

#### Funci√≥n: `ScrapeBothSorters()`
```go
func (cs *ChartScraper) ScrapeBothSorters() ([]*ChartData, error)
```
**Descripci√≥n:** Captura datos de ambos sorters (1 y 2)  
**Manejo de errores:** Contin√∫a aunque un sorter falle

#### Funci√≥n: `GetCalibreDistribution()`
```go
func (cd *ChartData) GetCalibreDistribution() map[string]float64
```
**Descripci√≥n:** Agrupa porcentajes por tipo de calibre  
**Ejemplo:**
```
Input (SKUs completos):
  "4J-D-SANTINA-C5WFTFG": 26%
  "4J-L-SANTINA-C5CZMG": 10%
  "3J-D-SANTINA-C5WFTFG": 33%

Output (por calibre):
  "Cuadruple_Jumbo": 36%  (26 + 10)
  "Triple_Jumbo": 33%
```

---

### 3. Funci√≥n: `getSalidasForSKU()` (Nuevo)

```go
func getSalidasForSKU(assignments []Assignment, sorterID int, sku string) string
```
**Responsabilidad:** Obtener las l√≠neas de selladora donde est√° asignado un SKU  
**Descripci√≥n:** Busca todos los assignments de un SKU espec√≠fico en un sorter y retorna las l√≠neas formateadas

**Algoritmo:**
```
1. Crear lista vac√≠a de salidas
2. FOR cada assignment en assignments:
   SI assignment.SorterID == sorterID Y assignment.SKU == sku:
     SI salida NO est√° en lista (evitar duplicados):
       Agregar assignment.Salida a lista
3. Ordenar salidas num√©ricamente
4. Formatear como "L1 L2 L3"
5. RETURN string formateado
```

**Ejemplo de uso:**
```go
assignments := []Assignment{
  {Salida: 2, SKU: "4J-D-LAPINS-C5WFTFG", SorterID: 1},
  {Salida: 7, SKU: "4J-D-LAPINS-C5WFTFG", SorterID: 1},
  {Salida: 3, SKU: "3J-L-LAPINS-C5WFTFG", SorterID: 1},
}

lineas := getSalidasForSKU(assignments, 1, "4J-D-LAPINS-C5WFTFG")
// Output: "L2 L7"
```

**Prop√≥sito:** Mostrar al usuario en qu√© l√≠neas f√≠sicas (selladoras) est√° configurado cada SKU, permitiendo verificar la configuraci√≥n del sistema.

---

#### Funci√≥n: `exportToCSV()`
```go
func exportToCSV(snapshot DataSnapshot) error
```

**Descripci√≥n:** Exporta los datos de calibres a formato CSV para entrenamiento de modelos ML.

**Input:** DataSnapshot con chart_data y distribuciones  
**Output:** Archivo `training_data/training_data.csv`

**Estructura del CSV:**
```csv
timestamp;sorter_id;sku;calibre;calidad;variedad;lineas;porcentaje;total_skus_activos
2025-11-27 16:53:59;1;4J-D-SANTINA-C5WFTFG;4J;D;SANTINA;L2 L7;26.0;9
2025-11-27 16:53:59;1;3J-D-SANTINA-C5WFTFG;3J;D;SANTINA;L3 L5;33.0;9
```

**Formato del archivo:**
- **Delimitador:** Punto y coma (`;`) para compatibilidad con Excel en espa√±ol
- **Codificaci√≥n:** UTF-8
- **Modo:** Append (agrega datos sin borrar registros anteriores)

**Columnas:**
- `timestamp`: Fecha/hora de la captura
- `sorter_id`: ID del sorter (1 o 2)
- `sku`: C√≥digo completo del producto
- `calibre`: Calibre de la fruta (extra√≠do del SKU)
- `calidad`: Calidad de la fruta (extra√≠do del SKU)
- `variedad`: Variedad de la fruta (extra√≠do del SKU)
- `lineas`: L√≠neas de selladora asignadas (ej: "L2 L7")
- `porcentaje`: Porcentaje real del gr√°fico
- `total_skus_activos`: Total de SKUs activos en ese sorter

**Algoritmo:**
```
1. Verificar si archivo existe (para determinar si escribir headers)
2. Abrir archivo en modo append (O_APPEND | O_CREATE)
3. Configurar writer con delimitador ';'
4. Si archivo es nuevo, escribir headers
5. Para cada sorter con datos de gr√°fico:
   a. Obtener assignments del sorter
   b. Para cada SKU con porcentaje:
      - Parsear SKU para extraer calibre, calidad, variedad
      - Obtener l√≠neas con getSalidasForSKU() (normalizado)
      - Escribir fila con todos los datos
6. Flush y cerrar archivo
```

**Normalizaci√≥n de SKUs:**
- Los SKUs del gr√°fico pueden tener diferente capitalizaci√≥n (ej: "Lapins" vs "LAPINS")
- `getSalidasForSKU()` normaliza a may√∫sculas para el match correcto
- Garantiza que las l√≠neas se asignen correctamente a cada SKU

**Parseo de SKU:**
```
SKU: "4J-D-SANTINA-C5WFTFG"
  ‚Üì
Calibre: "4J"
Calidad: "D"
Variedad: "SANTINA"
```

**Prop√≥sito:** Generar dataset estructurado para entrenar modelos ML que detecten porcentajes de calibres autom√°ticamente.

---

#### Funci√≥n: `loadConfig()`
```go
func loadConfig()
```

**Descripci√≥n:** Carga la configuraci√≥n desde `config.yaml` y actualiza las variables globales del sistema.

**Algoritmo:**
```
1. Leer archivo config.yaml
2. Parsear YAML a struct Config
3. Actualizar variables globales:
   - baseURL desde config.Packing.URL
   - checkInterval desde config.Monitor.IntervaloSegundos
   - captureCharts desde config.Monitor.CaptureCharts
   - datasetFolder desde config.Data.Folder
4. Recalcular rutas de archivos derivadas
5. Mostrar confirmaci√≥n con info del packing
```

**Manejo de errores:** Si falla la carga del YAML, usa valores por defecto y contin√∫a.

**Ejemplo de output:**
```
‚úì Configuraci√≥n cargada: Danich Cerezas (cereza) - 2 sorters, 7 l√≠neas
```

---

## üìä Modelos de Datos

### Config (YAML Structs)

```go
type PackingConfig struct {
    Name    string `yaml:"name"`
    URL     string `yaml:"url"`
    Sorters int    `yaml:"sorters"`
    Lineas  int    `yaml:"lineas"`
    Fruta   string `yaml:"fruta"`
}

type MonitorConfig struct {
    IntervaloSegundos int  `yaml:"intervalo_segundos"`
    CaptureCharts     bool `yaml:"capture_charts"`
}

type DataConfig struct {
    Folder string `yaml:"folder"`
}

type Config struct {
    Packing PackingConfig `yaml:"packing"`
    Monitor MonitorConfig `yaml:"monitor"`
    Data    DataConfig    `yaml:"data"`
}
```

**Fuente:** Archivo `config.yaml`  
**Prop√≥sito:** Configuraci√≥n flexible del sistema para diferentes packings

---

### Assignment
```go
type Assignment struct {
    Salida   int    `json:"salida"`    // N√∫mero de salida (1-7)
    SKU      string `json:"sku"`       // C√≥digo del producto
    SorterID int    `json:"sorter_id"` // ID del sorter (1 o 2)
}
```
**Fuente:** API HTTP  
**Ejemplo:**
```json
{
  "salida": 3,
  "sku": "4J-D-SANTINA-C5WFTFG",
  "sorter_id": 1
}
```

---

### ChartData
```go
type ChartData struct {
    SorterID    int                `json:"sorter_id"`
    Timestamp   time.Time          `json:"timestamp"`
    Percentages map[string]float64 `json:"percentages"`   // SKU ‚Üí %
    OrderedSKUs []string           `json:"ordered_skus"`  // Orden del gr√°fico
    TotalSKUs   int                `json:"total_skus"`
}
```
**Fuente:** Scraping con chromedp  
**Ejemplo:**
```json
{
  "sorter_id": 1,
  "timestamp": "2025-11-27T11:47:50Z",
  "percentages": {
    "4J-D-SANTINA-C5WFTFG": 26,
    "3J-D-SANTINA-C5WFTFG": 33
  },
  "ordered_skus": [
    "4J-D-SANTINA-C5WFTFG",
    "3J-D-SANTINA-C5CZMG",
    "3J-D-SANTINA-C5WFTFG"
  ],
  "total_skus": 9
}
```

---

### CalibreDistribution
```go
type CalibreDistribution struct {
    Count      int     `json:"count"`      // Cantidad de assignments
    Percentage float64 `json:"percentage"` // Porcentaje real del gr√°fico
}
```
**Nota importante:** `Count` no se usa actualmente (siempre 0) porque los porcentajes provienen directamente del gr√°fico, no de conteos manuales.

---

### DataSnapshot
```go
type DataSnapshot struct {
    Timestamp   string                     `json:"timestamp"`
    DateTime    time.Time                  `json:"datetime"`
    Assignments []Assignment               `json:"assignments"`
    TotalCount  int                        `json:"total_count"`
    BySorter    map[int]int                `json:"by_sorter"`
    BySalida    map[int]int                `json:"by_salida"`
    ChartData   map[int]*ChartData         `json:"chart_data,omitempty"`
    
    // Distribuciones multidimensionales
    CalibrePercent        map[string]float64                        `json:"calibre_percent,omitempty"`
    CalibreBySorter       map[int]map[string]CalibreDistribution    `json:"calibre_by_sorter,omitempty"`
    CalibreBySalida       map[int]map[string]CalibreDistribution    `json:"calibre_by_salida,omitempty"`
    CalibreBySorterSalida map[string]map[string]CalibreDistribution `json:"calibre_by_sorter_salida,omitempty"`
}
```

**Estructura de datos:**
```
DataSnapshot
‚îú‚îÄ‚îÄ timestamp: "2025-11-27 11:47:50"
‚îú‚îÄ‚îÄ assignments: [...]
‚îú‚îÄ‚îÄ chart_data:
‚îÇ   ‚îú‚îÄ‚îÄ [1]: ChartData del Sorter 1
‚îÇ   ‚îî‚îÄ‚îÄ [2]: ChartData del Sorter 2
‚îÇ
‚îú‚îÄ‚îÄ calibre_percent: (GLOBAL)
‚îÇ   ‚îú‚îÄ‚îÄ "4J-D-SANTINA-C5WFTFG": 28%
‚îÇ   ‚îî‚îÄ‚îÄ "3J-D-SANTINA-C5WFTFG": 35%
‚îÇ
‚îú‚îÄ‚îÄ calibre_by_sorter:
‚îÇ   ‚îú‚îÄ‚îÄ [1]: (Sorter 1)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ "4J-D-SANTINA-C5WFTFG": {Percentage: 26}
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ "3J-D-SANTINA-C5WFTFG": {Percentage: 33}
‚îÇ   ‚îî‚îÄ‚îÄ [2]: (Sorter 2)
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ calibre_by_salida:
‚îÇ   ‚îú‚îÄ‚îÄ [1]: (Salida 1)
‚îÇ   ‚îú‚îÄ‚îÄ [2]: (Salida 2)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ calibre_by_sorter_salida:
    ‚îú‚îÄ‚îÄ "1-1": (Sorter 1, Salida 1)
    ‚îú‚îÄ‚îÄ "1-2": (Sorter 1, Salida 2)
    ‚îî‚îÄ‚îÄ ...
```

---

### TrainingDataset
```go
type TrainingDataset struct {
    CollectionStart time.Time      `json:"collection_start"`
    CollectionEnd   time.Time      `json:"collection_end"`
    TotalSnapshots  int            `json:"total_snapshots"`
    Snapshots       []DataSnapshot `json:"snapshots"`
}
```
**Prop√≥sito:** Contenedor de todos los snapshots recolectados  
**Persistencia:** `training_data/dataset.json`

---

### ChangeLog
```go
type ChangeLog struct {
    Timestamp   string               `json:"timestamp"`
    ChangeType  string               `json:"change_type"`
    Added       []Assignment         `json:"added,omitempty"`
    Removed     []Assignment         `json:"removed,omitempty"`
    Modified    []ModifiedAssignment `json:"modified,omitempty"`
    Description string               `json:"description"`
}
```
**Prop√≥sito:** Registrar cambios detectados en assignments  
**Tipos de cambios:**
- `update`: Cambios en assignments existentes
- `initial`: Primera captura del sistema

---

## üßÆ Algoritmos y L√≥gica

### 1. Detecci√≥n de Cambios

**Objetivo:** Identificar diferencias entre dos estados de assignments

**Algoritmo:**
```
INPUT: old[]Assignment, new[]Assignment
OUTPUT: ChangeDetail{Added, Removed, Modified}

1. Crear mapa oldMap: key = "SKU-SorterID-Salida" ‚Üí Assignment
2. Crear mapa newMap: similar

3. DETECTAR REMOVED:
   FOR cada key en oldMap:
     SI key NO existe en newMap:
       Agregar oldMap[key] a lista Removed

4. DETECTAR ADDED y MODIFIED:
   FOR cada key en newMap:
     SI key NO existe en oldMap:
       Agregar newMap[key] a lista Added
     SI NO:
       SI oldMap[key] != newMap[key]:
         Agregar {Old: oldMap[key], New: newMap[key]} a Modified

5. RETURN ChangeDetail{Added, Removed, Modified}
```

**Complejidad:** O(n + m) donde n = len(old), m = len(new)

---

### 2. Extracci√≥n de Calibre

**Objetivo:** Extraer el tipo de calibre desde un SKU completo

**Algoritmo:**
```go
func extractCalibre(sku string) string {
    // Caso especial: descarte
    SI sku == "descarte" (case-insensitive):
        RETURN "Descarte"
    
    // Split por gui√≥n: "4J-D-SANTINA-C5WFTFG" ‚Üí ["4J", "D", "SANTINA", "C5WFTFG"]
    parts = sku.split("-")
    calibre = parts[0]
    
    // Mapeo a nombres completos
    SWITCH calibre:
        "J"   ‚Üí RETURN "Jumbo"
        "2J"  ‚Üí RETURN "Doble_Jumbo"
        "3J"  ‚Üí RETURN "Triple_Jumbo"
        "4J"  ‚Üí RETURN "Cuadruple_Jumbo"
        "XL"  ‚Üí RETURN "Extra_Large"
        DEFAULT ‚Üí RETURN calibre (sin cambios)
}
```

**Casos de prueba:**
```
"4J-D-SANTINA-C5WFTFG"  ‚Üí "Cuadruple_Jumbo"
"J-D-SANTINA-C5CZMG"    ‚Üí "Jumbo"
"XL-D-SANTINA-C5CZGR"   ‚Üí "Extra_Large"
"DESCARTE"              ‚Üí "Descarte"
```

---

### 3. C√°lculo de Distribuci√≥n Global

**Objetivo:** Promediar porcentajes entre sorters para obtener distribuci√≥n global

**Algoritmo:**
```
INPUT: chartDataList []*ChartData (datos de ambos sorters)
OUTPUT: map[string]float64 (SKU ‚Üí porcentaje promedio)

1. Inicializar resultado = map vac√≠o

2. AGREGAR datos del Sorter 1:
   FOR cada (sku, percent) en chartDataList[0].Percentages:
     resultado[sku] = percent

3. SI hay Sorter 2 (len(chartDataList) > 1):
   FOR cada (sku, percent) en chartDataList[1].Percentages:
     SI sku existe en resultado:
       resultado[sku] = (resultado[sku] + percent) / 2.0
     SI NO:
       resultado[sku] = percent

4. RETURN resultado
```

**Ejemplo:**
```
Sorter 1: {"4J-D-SANTINA": 30%, "3J-D-SANTINA": 40%}
Sorter 2: {"4J-D-SANTINA": 26%, "3J-D-SANTINA": 38%, "2J-D-SANTINA": 20%}

Resultado:
  "4J-D-SANTINA": (30 + 26) / 2 = 28%
  "3J-D-SANTINA": (40 + 38) / 2 = 39%
  "2J-D-SANTINA": 20%  (solo en Sorter 2)
```

---

### 4. Mapeo de Porcentajes a Salidas

**Objetivo:** Asociar porcentajes del gr√°fico con salidas f√≠sicas

**Algoritmo:**
```
INPUT: 
  - chartData: ChartData (porcentajes por SKU)
  - assignments: []Assignment (asignaciones SKU ‚Üí Salida)

OUTPUT: map[int]map[string]CalibreDistribution (Salida ‚Üí SKU ‚Üí Distribuci√≥n)

1. Inicializar resultado = map vac√≠o

2. FOR cada assignment en assignments:
   SI assignment.SorterID == chartData.SorterID:
     sku = assignment.SKU
     salida = assignment.Salida
     
     SI sku existe en chartData.Percentages:
       realPercent = chartData.Percentages[sku]
       
       // Crear entrada para esta salida si no existe
       SI resultado[salida] es nil:
         resultado[salida] = map vac√≠o
       
       // Guardar porcentaje real
       resultado[salida][sku] = CalibreDistribution{
         Count: 1,
         Percentage: realPercent
       }

3. RETURN resultado
```

**Concepto clave:** Los porcentajes NO se calculan contando assignments. Se usan los valores **reales del gr√°fico** que provienen de sensores del sorter.

---

## ‚öôÔ∏è Configuraci√≥n

### Sistema de Configuraci√≥n Flexible (config.yaml)

El sistema utiliza archivos YAML para m√°xima flexibilidad y adaptaci√≥n a cualquier packing.

**Archivo:** `config.yaml`
```yaml
# Informaci√≥n del packing (un packing a la vez)
packing:
  name: "Danich Cerezas"
  url: "http://192.168.121.2"
  sorters: 2
  lineas: 7
  fruta: "cereza"

# Configuraci√≥n del monitoreo
monitor:
  intervalo_segundos: 30
  capture_charts: true

# Rutas de datos
data:
  folder: "training_data"
```

**Filosof√≠a del Sistema:**
- ‚úÖ **Un packing a la vez:** Cada packing tiene su propio servidor y configuraci√≥n
- ‚úÖ **Completamente maleable:** Solo edita el YAML para cambiar de packing
- ‚úÖ **Sin c√≥digo hardcoded:** Todas las variables se cargan del YAML
- ‚úÖ **Adaptable:** Funciona con cualquier n√∫mero de sorters, l√≠neas y tipos de fruta

### Variables Globales (`pkg/monitor/monitoreo.go`)

```go
var (
    // Configuraci√≥n de red (cargada desde YAML)
    baseURL        string
    assignmentsURL string
    
    // Configuraci√≥n de monitoreo (cargada desde YAML)
    checkInterval  time.Duration
    captureCharts  bool
    
    // Configuraci√≥n de persistencia (cargada desde YAML)
    datasetFolder       string
    currentSnapshotFile string
    datasetFile         string
    changesLogFile      string
    lastAssignmentsFile = "last_assignments.json"
)
```

### Modificar configuraci√≥n:

**Para cambiar de packing**, simplemente edita `config.yaml`:

```yaml
packing:
  name: "Packing XYZ"
  url: "http://192.168.1.100"    # Diferente servidor
  sorters: 3                      # M√°s sorters
  lineas: 12                      # M√°s l√≠neas
  fruta: "arandano"               # Diferente fruta

monitor:
  intervalo_segundos: 60          # Monitoreo cada minuto
  capture_charts: false           # Sin captura de gr√°ficos

data:
  folder: "training_data_xyz"     # Carpeta espec√≠fica
```

**No requiere recompilar el c√≥digo.** Solo reinicia el monitor.

---

## üîå Dependencias Externas

### go.mod completo

```go
module danich

go 1.25.4

require (
    github.com/PuerkitoBio/goquery v1.11.0
    github.com/andybalholm/cascadia v1.3.3
    github.com/chromedp/cdproto v0.0.0-20250803210736-d308e07a266d
    github.com/chromedp/chromedp v0.14.2
    github.com/chromedp/sysutil v1.1.0
    github.com/go-json-experiment/json v0.0.0-20251027170946-4849db3c2f7e
    github.com/gobwas/httphead v0.1.0
    github.com/gobwas/pool v0.2.1
    github.com/gobwas/ws v1.4.0
    golang.org/x/net v0.47.0
    golang.org/x/sys v0.38.0
)
```

### Descripci√≥n de dependencias:

| Paquete | Versi√≥n | Prop√≥sito |
|---------|---------|-----------|
| `chromedp/chromedp` | v0.14.2 | Control de Chrome headless |
| `chromedp/cdproto` | latest | Protocolo DevTools de Chrome |
| `chromedp/sysutil` | v1.1.0 | Utilidades del sistema para chromedp |
| `PuerkitoBio/goquery` | v1.11.0 | Parsing HTML (estilo jQuery) |
| `andybalholm/cascadia` | v1.3.3 | Selectores CSS (usado por goquery) |
| `gobwas/ws` | v1.4.0 | WebSocket client (para chromedp) |
| `golang.org/x/net` | v0.47.0 | Extensiones de red de Go |
| `golang.org/x/sys` | v0.38.0 | Llamadas al sistema |

### Instalaci√≥n de dependencias:

```bash
go mod download
```

---

## üìã Casos de Uso

### Caso 1: Monitoreo Continuo

**Actor:** Sistema automatizado  
**Objetivo:** Recolectar datos cada 30 segundos para ML

**Flujo:**
```
1. Usuario ejecuta: ./bin/monitor.exe
2. Sistema inicializa:
   - Carga dataset existente
   - Inicializa ChartScraper
3. LOOP infinito:
   a. Obtener assignments del API
   b. Capturar gr√°ficos de ambos sorters
   c. Crear snapshot con distribuciones
   d. Detectar cambios vs estado anterior
   e. Guardar en dataset.json
   f. Mostrar estad√≠sticas
   g. Sleep 30 segundos
4. Usuario detiene con Ctrl+C
```

**Output generado:**
- `training_data/dataset.json` (creciente)
- `training_data/current_snapshot.json` (actualizado)
- `training_data/changes_log.json` (append)
- `training_data/snapshots_YYYYMMDD.json` (backup diario)
- `training_data/training_data.csv` (dataset para ML)

---

### Caso 2: Captura √önica para Testing

**Actor:** Desarrollador  
**Objetivo:** Probar el scraper sin loop continuo

**Flujo:**
```
1. Desarrollador ejecuta: ./bin/capture-charts.exe
2. Sistema:
   a. Crea ChartScraper
   b. Captura datos de Sorter 1
   c. Captura datos de Sorter 2
   d. Muestra resultados en consola
   e. Guarda en chart_data_captured.json
3. Termina la ejecuci√≥n
```

**Output:**
```
=== Capturando datos de gr√°ficos de ambos sorters ===

Sorter: 1
Timestamp: 2025-11-27 11:47:50
Total SKUs: 9
Detalle por SKU:
  4J-D-SANTINA-C5WFTFG: 26%   L2 L7
  3J-D-SANTINA-C5WFTFG: 33%   L3 L5
  ...

‚úì Datos guardados en: chart_data_captured.json
```

---

### Caso 3: An√°lisis de Cambios

**Actor:** Sistema  
**Objetivo:** Detectar cu√°ndo cambian las asignaciones

**Flujo:**
```
1. Sistema tiene estado previo en last_assignments.json
2. Obtiene nuevo estado del API
3. Ejecuta hasChanges():
   - Serializa ambos estados a JSON
   - Compara bytes
4. SI hay cambios:
   a. Ejecuta detectChanges()
   b. Identifica: Added, Removed, Modified
   c. Muestra en consola:
      üîî ¬°CAMBIOS DETECTADOS!
      + Agregados: 2 assignments
      - Eliminados: 1 assignment
      ‚âà Modificados: 3 assignments
   d. Guarda en changes_log.json
5. SI NO hay cambios:
   Muestra: ‚úì Sin cambios
```

---

## üéì Machine Learning y Entrenamiento

### Visi√≥n General del Pipeline ML

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 1: RECOLECCI√ìN (Go - monitor)                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ
‚îÇ  Loop 30s ‚Üí dataset.json + changes_log.json + CSV      ‚îÇ
‚îÇ  Duraci√≥n: 1-2 semanas                                  ‚îÇ
‚îÇ  Objetivo: >100 cambios detectados                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 2: INFERENCIA (Go - infer-decisions)             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ
‚îÇ  Analiza cambios hist√≥ricos autom√°ticamente             ‚îÇ
‚îÇ  Output: decisiones_training.csv con etiquetas          ‚îÇ
‚îÇ  Objetivo: Dataset etiquetado sin intervenci√≥n humana   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 3: ENTRENAMIENTO (Python - train_model.py)       ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ
‚îÇ  XGBoost Classifier con 18 features                     ‚îÇ
‚îÇ  Output: decision_model.pkl + metrics                   ‚îÇ
‚îÇ  Objetivo: Predecir raz√≥n de decisi√≥n con >80% accuracy‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 4: PREDICCI√ìN (Python - usar modelo)             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ
‚îÇ  Cargar modelo entrenado                                ‚îÇ
‚îÇ  Predecir raz√≥n de nuevos cambios                       ‚îÇ
‚îÇ  Explicar por qu√© se tom√≥ una decisi√≥n                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Dataset de Entrenamiento

**Archivo:** `training_data/decisiones_training.csv`

**Estructura:**
```csv
timestamp;sku;calibre;variedad;de_sorter;a_sorter;de_lineas;a_lineas;porcentaje_antes_s1;porcentaje_antes_s2;diferencia_antes;porcentaje_despues_s1;porcentaje_despues_s2;diferencia_despues;mejora_balance;impacto_balance;total_skus_antes_s1;total_skus_antes_s2;razon_inferida;confianza
```

**Columnas (20 total):**

| Columna | Tipo | Descripci√≥n | Ejemplo |
|---------|------|-------------|---------|
| `timestamp` | string | Momento del cambio | "2025-11-27 17:08:02" |
| `sku` | string | SKU completo | "4J-D-LAPINS-C5WFTFG" |
| `calibre` | string | Calibre extra√≠do | "4J" |
| `variedad` | string | Variedad de fruta | "LAPINS" |
| `de_sorter` | int | Sorter origen | 1 |
| `a_sorter` | int | Sorter destino | 2 |
| `de_lineas` | string | L√≠neas origen | "L2 L7" |
| `a_lineas` | string | L√≠neas destino | "L3 L5" |
| `porcentaje_antes_s1` | float | % Sorter 1 antes | 26.0 |
| `porcentaje_antes_s2` | float | % Sorter 2 antes | 30.0 |
| `diferencia_antes` | float | Diferencia antes | 4.0 |
| `porcentaje_despues_s1` | float | % Sorter 1 despu√©s | 28.0 |
| `porcentaje_despues_s2` | float | % Sorter 2 despu√©s | 28.0 |
| `diferencia_despues` | float | Diferencia despu√©s | 0.0 |
| `mejora_balance` | bool | ¬øMejor√≥ balance? | true |
| `impacto_balance` | float | Reducci√≥n diferencia | 4.0 |
| `total_skus_antes_s1` | int | SKUs activos S1 | 11 |
| `total_skus_antes_s2` | int | SKUs activos S2 | 9 |
| `razon_inferida` | string | **TARGET** Etiqueta | "desbalance_moderado" |
| `confianza` | float | Confianza inferencia | 0.85 |

### Clases de Decisi√≥n

El modelo clasifica decisiones en **6 categor√≠as**:

| Clase | Descripci√≥n | Criterio | Frecuencia t√≠pica |
|-------|-------------|----------|-------------------|
| `desbalance_severo` | Diferencia cr√≠tica | diffAntes > 8% | 15% |
| `desbalance_moderado` | Diferencia moderada | 5% < diffAntes ‚â§ 8% | 35% |
| `sobrecarga_sorter` | Sorter sobrecargado | carga > 80% | 5% |
| `optimizacion_preventiva` | Mejora proactiva | diffAntes < 5% Y mejora | 10% |
| `redistribucion_calibre` | Cambio de calibre | Cambio tipo fruta | 20% |
| `ajuste_operacional` | Otras razones | Resto de casos | 15% |

### Archivo: `train_model.py`

**Prop√≥sito:** Script de entrenamiento del modelo XGBoost

**Dependencias:**
```python
pandas==2.3.3
scikit-learn==1.7.2
xgboost==3.1.2
joblib==1.5.2
```

**Instalaci√≥n:**
```bash
cd MonitoreoDanich
python -m venv venv
source venv/Scripts/activate  # Windows Git Bash
pip install pandas scikit-learn xgboost joblib
```

**Ejecuci√≥n:**
```bash
python train_model.py
```

### Arquitectura del Modelo

#### 1. Carga y Preparaci√≥n de Datos

```python
# Cargar CSV con semicolon delimiter
df = pd.read_csv(
    'training_data/decisiones_training.csv',
    sep=';',
    encoding='utf-8'
)

# Validar m√≠nimo de muestras
if len(df) < 50:
    print(f"‚ö†Ô∏è  Solo {len(df)} muestras. Recomendado: >100")
    # Continuar de todas formas para testing
```

#### 2. Feature Engineering

**Features Base (9):**
- `de_sorter`, `a_sorter`
- `porcentaje_antes_s1`, `porcentaje_antes_s2`
- `diferencia_antes`
- `porcentaje_despues_s1`, `porcentaje_despues_s2`
- `diferencia_despues`
- `total_skus_antes_s1`, `total_skus_antes_s2`

**Features Derivadas (5):**
```python
# Mejora absoluta en balance
df['mejora_absoluta'] = df['diferencia_antes'] - df['diferencia_despues']

# Mejora relativa (%)
df['mejora_relativa'] = (
    (df['diferencia_antes'] - df['diferencia_despues']) / 
    (df['diferencia_antes'] + 1e-6)
)

# Carga total de cada sorter
df['carga_antes_s1'] = df['porcentaje_antes_s1']  # Simplificado
df['carga_antes_s2'] = df['porcentaje_antes_s2']

# Diferencia de carga entre sorters
df['diff_carga'] = abs(df['carga_antes_s1'] - df['carga_antes_s2'])
```

**Features Categ√≥ricas:**
```python
# One-hot encoding de calibre
calibre_dummies = pd.get_dummies(df['calibre'], prefix='calibre')
df = pd.concat([df, calibre_dummies], axis=1)
```

**Total Features:** 18
- 9 base + 5 derivadas + 4 calibre dummies (ej: J, 2J, 3J, 4J)

#### 3. Preparaci√≥n Target

```python
# Encode target (razon_inferida)
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['razon_inferida'])

# Clases:
# 0: ajuste_operacional
# 1: desbalance_moderado
# 2: desbalance_severo
# 3: optimizacion_preventiva
# 4: redistribucion_calibre
# 5: sobrecarga_sorter
```

#### 4. Train/Test Split

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
    # NO stratify si hay clases con <2 muestras
)
```

**Problema conocido:** Con pocos datos (<50), algunas clases pueden tener solo 1 muestra, haciendo imposible stratify.

**Soluci√≥n:** Remover stratify y entrenar con distribuci√≥n natural.

#### 5. Modelo XGBoost

```python
model = XGBClassifier(
    n_estimators=100,        # N√∫mero de √°rboles
    max_depth=5,             # Profundidad m√°xima
    learning_rate=0.1,       # Tasa de aprendizaje
    subsample=0.8,           # Fracci√≥n de muestras
    colsample_bytree=0.8,    # Fracci√≥n de features
    random_state=42,
    eval_metric='mlogloss'   # M√©trica de evaluaci√≥n
)

model.fit(X_train, y_train)
```

**¬øPor qu√© XGBoost?**
- ‚úÖ Excelente con features tabulares
- ‚úÖ Maneja datos desbalanceados
- ‚úÖ Feature importance nativo
- ‚úÖ Robusto con pocos datos
- ‚úÖ No requiere escalado de features

#### 6. Evaluaci√≥n

```python
# Predicciones
y_pred = model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Reporte detallado
print(classification_report(
    y_test, 
    y_pred,
    target_names=label_encoder.classes_
))

# Feature Importance
importances = model.feature_importances_
for idx in np.argsort(importances)[::-1][:10]:
    print(f"{feature_names[idx]}: {importances[idx]:.3f}")
```

**Features m√°s importantes (t√≠pico):**
1. `mejora_absoluta`: 0.27
2. `impacto_balance`: 0.20
3. `diferencia_antes`: 0.15
4. `porcentaje_antes_s1`: 0.12
5. `diferencia_despues`: 0.10

#### 7. Persistencia

```python
# Guardar modelo
joblib.dump(model, 'decision_model.pkl')

# Guardar label encoder
joblib.dump(label_encoder, 'label_encoder.pkl')

# Guardar m√©tricas
metrics = {
    'accuracy': float(accuracy),
    'classification_report': classification_report(
        y_test, y_pred,
        target_names=label_encoder.classes_,
        output_dict=True
    ),
    'feature_importance': dict(zip(feature_names, importances.tolist())),
    'training_samples': len(X_train),
    'test_samples': len(X_test),
    'classes': label_encoder.classes_.tolist()
}

with open('training_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)
```

### Output del Entrenamiento

**Ejemplo con datos insuficientes (28 muestras):**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     ENTRENAMIENTO DE MODELO DE DECISIONES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Dataset: training_data/decisiones_training.csv

Cargando datos...
‚úì Total decisiones: 28

‚ö†Ô∏è  ADVERTENCIA: Solo 28 muestras disponibles
    Se recomienda al menos 100 muestras para entrenamiento robusto
    Continuando de todas formas...

Distribuci√≥n de clases:
  desbalance_moderado      : 12 (43%)
  redistribucion_calibre   : 8 (29%)
  optimizacion_preventiva  : 4 (14%)
  desbalance_severo        : 2 (7%)
  ajuste_operacional       : 2 (7%)
  sobrecarga_sorter        : 0 (0%)  ‚ö†Ô∏è  Clase sin muestras

Features generadas: 18
  - Base: 9
  - Derivadas: 5
  - Calibre (one-hot): 4

Split: 80% train (22), 20% test (6)

Entrenando XGBoost...
‚úì Modelo entrenado

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     RESULTADOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Accuracy (test): 0.50 (3/6)

Classification Report:
                          precision  recall  f1-score  support
desbalance_moderado          0.67     0.67     0.67       3
redistribucion_calibre       0.00     0.00     0.00       2
optimizacion_preventiva      0.00     0.00     0.00       1
desbalance_severo            0.00     0.00     0.00       0
ajuste_operacional           0.00     0.00     0.00       0

           accuracy                          0.50       6
          macro avg          0.13     0.13     0.13      6
       weighted avg          0.45     0.50     0.45      6

Top 10 Features:
  1. mejora_absoluta        : 0.270
  2. impacto_balance        : 0.201
  3. diferencia_antes       : 0.145
  4. porcentaje_antes_s1    : 0.118
  5. diferencia_despues     : 0.095
  6. mejora_relativa        : 0.067
  7. calibre_4J             : 0.053
  8. de_sorter              : 0.031
  9. carga_antes_s1         : 0.020
 10. total_skus_antes_s1    : 0.000

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úì Modelo guardado: decision_model.pkl
‚úì Label encoder: label_encoder.pkl
‚úì M√©tricas: training_metrics.json

‚ö†Ô∏è  RECOMENDACI√ìN:
   El modelo tiene baja accuracy (50%) debido a pocas muestras.
   Ejecuta el monitor por 1-2 semanas m√°s para obtener >100 cambios,
   luego vuelve a entrenar para mejor performance.
```

**Ejemplo con datos suficientes (>200 muestras):**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     ENTRENAMIENTO DE MODELO DE DECISIONES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Dataset: training_data/decisiones_training.csv

Cargando datos...
‚úì Total decisiones: 247

Distribuci√≥n de clases:
  desbalance_moderado      : 102 (41%)
  redistribucion_calibre   : 68 (28%)
  optimizacion_preventiva  : 32 (13%)
  ajuste_operacional       : 25 (10%)
  desbalance_severo        : 15 (6%)
  sobrecarga_sorter        : 5 (2%)

Features generadas: 18
Split: 80% train (197), 20% test (50)

Entrenando XGBoost...
‚úì Modelo entrenado

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     RESULTADOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Accuracy (test): 0.86 (43/50)  ‚úì Excelente

Classification Report:
                          precision  recall  f1-score  support
desbalance_moderado          0.90     0.95     0.92      20
redistribucion_calibre       0.85     0.79     0.82      14
optimizacion_preventiva      0.75     0.86     0.80       7
ajuste_operacional           0.80     0.67     0.73       6
desbalance_severo            1.00     0.67     0.80       3
sobrecarga_sorter            0.00     0.00     0.00       0

           accuracy                          0.86      50
          macro avg          0.72     0.66     0.68      50
       weighted avg          0.86     0.86     0.86      50

Top 10 Features:
  1. diferencia_antes       : 0.312  ‚≠ê
  2. mejora_absoluta        : 0.285  ‚≠ê
  3. impacto_balance        : 0.168
  4. porcentaje_antes_s1    : 0.092
  5. diferencia_despues     : 0.075
  6. carga_antes_s1         : 0.041
  7. calibre_4J             : 0.027

‚úì Modelo guardado: decision_model.pkl
‚úì Label encoder: label_encoder.pkl
‚úì M√©tricas: training_metrics.json

üéâ ¬°Modelo entrenado exitosamente con 86% accuracy!
   Listo para usar en producci√≥n.
```

### Uso del Modelo Entrenado

**Script ejemplo (`predict_decision.py`):**
```python
import joblib
import pandas as pd

# Cargar modelo y encoder
model = joblib.load('decision_model.pkl')
label_encoder = joblib.load('label_encoder.pkl')

# Datos de un nuevo cambio
new_data = pd.DataFrame([{
    'de_sorter': 1,
    'a_sorter': 2,
    'porcentaje_antes_s1': 30.0,
    'porcentaje_antes_s2': 22.0,
    'diferencia_antes': 8.0,
    'porcentaje_despues_s1': 26.0,
    'porcentaje_despues_s2': 26.0,
    'diferencia_despues': 0.0,
    'total_skus_antes_s1': 11,
    'total_skus_antes_s2': 9,
    'calibre': '4J',
    # ... agregar features derivadas ...
}])

# Feature engineering (igual que en training)
new_data['mejora_absoluta'] = new_data['diferencia_antes'] - new_data['diferencia_despues']
# ...

# Predicci√≥n
prediction = model.predict(new_data)
predicted_class = label_encoder.inverse_transform(prediction)[0]
probability = model.predict_proba(new_data)[0]

print(f"Raz√≥n predicha: {predicted_class}")
print(f"Confianza: {probability.max():.2f}")
print(f"Probabilidades:")
for cls, prob in zip(label_encoder.classes_, probability):
    print(f"  {cls}: {prob:.3f}")
```

**Output:**
```
Raz√≥n predicha: desbalance_severo
Confianza: 0.92
Probabilidades:
  desbalance_severo: 0.920
  desbalance_moderado: 0.055
  sobrecarga_sorter: 0.015
  optimizacion_preventiva: 0.008
  redistribucion_calibre: 0.002
  ajuste_operacional: 0.000
```

### Estrategia de Mejora del Modelo

#### Fase 1: Datos insuficientes (0-50 muestras)
- ‚úÖ Usar **Ollama prompting** para asesoramiento
- ‚è≥ Dejar monitor corriendo 1-2 semanas
- ‚è≥ NO entrenar modelo a√∫n

#### Fase 2: Datos m√≠nimos (50-100 muestras)
- ‚úÖ Entrenar modelo b√°sico (accuracy ~60-70%)
- ‚úÖ Usar para an√°lisis exploratorio
- ‚è≥ Seguir recolectando datos

#### Fase 3: Datos suficientes (100-200 muestras)
- ‚úÖ Entrenar modelo robusto (accuracy ~75-85%)
- ‚úÖ Usar en producci√≥n con precauci√≥n
- ‚úÖ Monitorear predicciones

#### Fase 4: Datos abundantes (>200 muestras)
- ‚úÖ Modelo confiable (accuracy >85%)
- ‚úÖ Producci√≥n completa
- ‚úÖ Tuning de hiperpar√°metros

### Integraci√≥n del Modelo en el Sistema

**Futuro:** Integrar predicciones en tiempo real

```go
// En pkg/advisor/predictor.go (futuro)
func PredictDecisionReason(change ChangeData) (string, float64, error) {
    // Llamar a Python script desde Go
    cmd := exec.Command("python", "predict_decision.py", 
        "--change", jsonEncode(change))
    
    output, err := cmd.Output()
    if err != nil {
        return "", 0, err
    }
    
    // Parsear resultado
    var result struct {
        Reason     string  `json:"reason"`
        Confidence float64 `json:"confidence"`
    }
    json.Unmarshal(output, &result)
    
    return result.Reason, result.Confidence, nil
}
```

**Uso en monitor:**
```go
// Despu√©s de detectChanges()
if hasChanges() {
    reason, confidence, _ := advisor.PredictDecisionReason(changeData)
    
    fmt.Printf("ü§ñ Predicci√≥n ML:\n")
    fmt.Printf("   Raz√≥n: %s\n", reason)
    fmt.Printf("   Confianza: %.0f%%\n", confidence*100)
}
```

---

## üîç Puntos Clave para Estudio

### 1. ¬øPor qu√© chromedp en lugar de HTTP simple?

**Respuesta:** Los gr√°ficos son generados con JavaScript (probablemente React/Vue). El HTML inicial no contiene los porcentajes. chromedp:
- Ejecuta el JavaScript
- Espera el renderizado
- Lee el DOM final

### 2. ¬øPor qu√© guardar OrderedSKUs?

**Respuesta:** El orden en el gr√°fico tiene significado (probablemente ordenado por importancia o frecuencia). Preservarlo permite:
- Mostrar datos igual que el gr√°fico original
- An√°lisis de patrones de ordenamiento
- Debugging (comparar con pantalla real)

### 3. ¬øPor qu√© Count siempre es 0 en CalibreDistribution?

**Respuesta:** Inicialmente se calculaban porcentajes contando assignments. Luego se descubri√≥ que no coincid√≠an con los porcentajes reales del gr√°fico (que provienen de sensores). Ahora:
- `Percentage` = dato real del gr√°fico ‚úÖ
- `Count` = obsoleto (se mantiene por compatibilidad JSON)

### 4. ¬øPor qu√© hay doble `/api/` en la URL?

**Respuesta:** Es una peculiaridad del backend existente:
```
http://192.168.121.2/api/api/assignments_list
                     ^   ^
                     1   2
```
Probablemente un prefijo de ruta en el router + endpoint espec√≠fico.

### 5. ¬øC√≥mo se mapean los SKUs a salidas?

**Respuesta:** El API devuelve assignments que dicen "este SKU debe ir a esta salida en este sorter". El gr√°fico dice "este SKU est√° saliendo al X%". Combin√°ndolos sabemos:
```
Assignment 1: "4J-D-SANTINA-C5WFTFG" ‚Üí Salida 3, Sorter 1
Assignment 2: "4J-D-SANTINA-C5WFTFG" ‚Üí Salida 5, Sorter 1
ChartData:    "4J-D-SANTINA-C5WFTFG" ‚Üí 26%
Conclusi√≥n:   Este SKU est√° en Salidas 3 y 5 con 26% total
Display:      "4J-D-SANTINA-C5WFTFG: 26%   L3 L5"
```

**Nota importante:** Un mismo SKU puede estar asignado a **m√∫ltiples l√≠neas/salidas** en el mismo sorter. Esto permite distribuir un producto en diferentes selladoras seg√∫n la configuraci√≥n de la planta.

---

## üõ†Ô∏è Comandos y Herramientas

### Comandos Go

#### 1. `monitor` - Monitoreo Continuo

**Archivo:** `cmd/monitor/main.go`  
**Compilar:**
```bash
go build -o bin/monitor.exe cmd/monitor/main.go
```

**Ejecutar:**
```bash
./bin/monitor.exe
```

**Funci√≥n:** Loop infinito cada 30s que:
- Captura assignments del API
- Scrapea gr√°ficos con chromedp
- Detecta cambios
- Exporta a CSV y JSON
- Muestra estad√≠sticas en consola

**Output continuo:**
```
‚úì Configuraci√≥n cargada: Danich Cerezas (cereza) - 2 sorters, 7 l√≠neas

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
 Monitoreo #1 - 2025-11-27 17:08:02
 Total snapshots: 1
 Tiempo activo: 0m 22s
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SORTER 1 (11 SKUs activos):
  4J-D-LAPINS-C5WFTFG: 26%   L2 L7
  3J-D-LAPINS-C5WFTFG: 33%   L5
  ...

SORTER 2 (9 SKUs activos):
  4J-D-LAPINS-C5WFTFG: 25%   L4
  3J-D-LAPINS-C5WFTFG: 35%   L1 L2
  ...

‚úì Sin cambios en assignments
Pr√≥xima verificaci√≥n en 30s...
```

**Detener:** `Ctrl+C`

---

#### 2. `capture-charts` - Testing de Scraper

**Archivo:** `cmd/capture-charts/main.go`  
**Compilar:**
```bash
go build -o bin/capture-charts.exe cmd/capture-charts/main.go
```

**Ejecutar:**
```bash
./bin/capture-charts.exe
```

**Funci√≥n:** Ejecuci√≥n √∫nica (no loop) para probar el scraper:
- Captura datos de ambos sorters
- Muestra en consola
- Guarda en `chart_data_captured.json`
- Termina

**Uso:** Testing y debugging del scraper sin ejecutar todo el monitor.

---

#### 3. `infer-decisions` - Generaci√≥n de Dataset ML

**Archivo:** `cmd/infer-decisions/main.go`  
**Compilar:**
```bash
go build -o bin/infer-decisions.exe cmd/infer-decisions/main.go
```

**Ejecutar:**
```bash
./bin/infer-decisions.exe
```

**Funci√≥n:** Inferencia autom√°tica de decisiones:
- Lee `changes_log.json` y `dataset.json`
- Detecta movimientos de SKUs
- Infiere razones autom√°ticamente (6 categor√≠as)
- Calcula confianza (0-1)
- Genera `decisiones_inferidas.json` (detalle completo)
- Genera `decisiones_training.csv` (para ML)
- Muestra estad√≠sticas

**Output:**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     INFERENCIA AUTOM√ÅTICA DE DECISIONES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Analizando cambios hist√≥ricos...
‚úì Cargados 12 cambios de changes_log.json
‚úì Cargados 156 snapshots de dataset.json

Procesando...
  Change 1: Detectado movimiento de 4J-D-LAPINS
  Change 2: No se detect√≥ movimiento claro (skip)
  ...

Total decisiones inferidas: 28

Distribuci√≥n por raz√≥n:
  desbalance_moderado      : 12 (43%)
  redistribucion_calibre   : 8 (29%)
  ...

Confianza promedio: 0.42

‚úì Datos guardados en:
  - training_data/decisiones_inferidas.json
  - training_data/decisiones_training.csv
```

**Cu√°ndo ejecutar:**
- Despu√©s de 1-2 semanas de monitoreo continuo
- Cuando tengas >10 cambios detectados
- Antes de entrenar el modelo ML

---

#### 4. `analyze-data` - An√°lisis de Calidad

**Archivo:** `cmd/analyze-data/main.go`  
**Status:** Implementado pero no usado actualmente  
**Compilar:**
```bash
go build -o bin/analyze-data.exe cmd/analyze-data/main.go
```

**Funci√≥n:** An√°lisis de calidad y cobertura de datos (futuro).

---

### Comandos Python

#### 1. `train_model.py` - Entrenamiento ML

**Archivo:** `train_model.py`  
**Requisitos:**
```bash
pip install pandas scikit-learn xgboost joblib
```

**Ejecutar:**
```bash
python train_model.py
```

**Funci√≥n:**
- Carga `decisiones_training.csv`
- Feature engineering (18 features)
- Entrena XGBoost Classifier
- Eval√∫a con test set
- Guarda modelo, encoder y m√©tricas

**Pre-requisito:** Haber ejecutado `infer-decisions` antes.

**Output:**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
     ENTRENAMIENTO DE MODELO DE DECISIONES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Dataset: training_data/decisiones_training.csv
Total decisiones: 247

Distribuci√≥n de clases: ...
Features generadas: 18
Split: 197 train / 50 test

Entrenando XGBoost...
‚úì Modelo entrenado

Accuracy (test): 0.86

‚úì Modelo guardado: decision_model.pkl
‚úì Label encoder: label_encoder.pkl
‚úì M√©tricas: training_metrics.json
```

---

### Configuraci√≥n del Entorno Python

#### Setup Inicial

```bash
# 1. Crear entorno virtual
python -m venv venv

# 2. Activar entorno
# Windows (Git Bash)
source venv/Scripts/activate

# Windows (CMD)
venv\Scripts\activate.bat

# Windows (PowerShell)
venv\Scripts\Activate.ps1

# 3. Instalar dependencias
pip install pandas scikit-learn xgboost joblib

# 4. Verificar instalaci√≥n
python -c "import pandas, sklearn, xgboost, joblib; print('OK')"
```

#### Activaci√≥n R√°pida (cada sesi√≥n)

```bash
source venv/Scripts/activate
python train_model.py
```

---

### Workflow Completo

#### Workflow 1: Primera Ejecuci√≥n (Setup)

```bash
# 1. Compilar monitor (punto de entrada √∫nico)
go build -o bin/monitor.exe cmd/monitor/main.go

# Opcional: Compilar herramientas adicionales
go build -o bin/capture-charts.exe cmd/capture-charts/main.go
go build -o bin/infer-decisions.exe cmd/infer-decisions/main.go

# 2. Probar scraper (opcional)
./bin/capture-charts.exe

# 3. Configurar Python
python -m venv venv
source venv/Scripts/activate
pip install pandas scikit-learn xgboost joblib

# 4. Iniciar monitoreo continuo
./bin/monitor.exe
# Dejar corriendo 1-2 semanas...
```

#### Workflow 2: Generar Dataset ML (despu√©s de 1-2 semanas)

```bash
# 1. Detener monitor (Ctrl+C)

# 2. Generar decisiones inferidas
./bin/infer-decisions.exe
# Output: decisiones_training.csv

# 3. Entrenar modelo
source venv/Scripts/activate
python train_model.py
# Output: decision_model.pkl

# 4. Reiniciar monitor
./bin/monitor.exe
```

#### Workflow 3: Re-entrenar con m√°s datos (despu√©s de 1 mes)

```bash
# 1. Generar nuevo dataset
./bin/infer-decisions.exe
# Ahora tiene m√°s cambios (ej: 200+)

# 2. Re-entrenar modelo
python train_model.py
# Mejor accuracy (ej: 86%)

# 3. Comparar m√©tricas
cat training_metrics.json
```

---

## üöÄ Compilaci√≥n y Despliegue

### Compilar todos los comandos

```bash
# Monitor principal
go build -o bin/monitor.exe cmd/monitor/main.go

# Herramientas
go build -o bin/capture-charts.exe cmd/capture-charts/main.go
go build -o bin/infer-decisions.exe cmd/infer-decisions/main.go
go build -o bin/analyze-data.exe cmd/analyze-data/main.go

# Compilaci√≥n cross-platform (Linux desde Windows)
GOOS=linux GOARCH=amd64 go build -o bin/monitor cmd/monitor/main.go
```

### Desplegar en otro packing

```bash
# 1. Copiar binarios
cp bin/*.exe /path/to/otro/packing/

# 2. Editar config.yaml
nano config.yaml
# Cambiar: URL, sorters, l√≠neas, fruta

# 3. Ejecutar
./monitor.exe
```

**No requiere recompilar** - Todo configurable en YAML.

---

## üìö Referencias

### Documentaci√≥n oficial:

- **Go:** https://go.dev/doc/
- **chromedp:** https://github.com/chromedp/chromedp
- **goquery:** https://github.com/PuerkitoBio/goquery

### Conceptos Go importantes:

- **Goroutines y Concurrencia:** https://go.dev/tour/concurrency
- **Context:** https://go.dev/blog/context
- **JSON encoding:** https://go.dev/blog/json

### Chrome DevTools Protocol:

- **Documentaci√≥n:** https://chromedevtools.github.io/devtools-protocol/

---

## üß™ Testing y Debugging

### Probar scraper sin monitor:

```bash
./bin/capture-charts.exe
```

### Verificar conectividad con API:

```bash
curl http://192.168.121.2/api/api/assignments_list
```

### Ver logs de chromedp:

```go
// Agregar en chart_scraper.go
ctx, cancel = chromedp.NewContext(ctx, chromedp.WithDebugf(log.Printf))
```

### Validar JSON generado:

```bash
cat training_data/dataset.json | jq '.snapshots | length'
```

---

## üéì Resumen para Estudio

### Conceptos clave:

1. **Web Scraping con JavaScript:** chromedp permite interactuar con SPAs
2. **Arquitectura Hexagonal:** Separaci√≥n clara entre negocio e infraestructura
3. **Persistencia JSON:** Formato legible para an√°lisis posterior
4. **Event Detection:** Comparaci√≥n de estados para detectar cambios
5. **Data Aggregation:** M√∫ltiples dimensiones de an√°lisis (sorter, salida, combinado)
6. **Multi-line Assignment:** Un SKU puede estar en m√∫ltiples l√≠neas de selladora simult√°neamente

### Flujo de aprendizaje sugerido:

1. ‚úÖ Entender el prop√≥sito del sistema
2. ‚úÖ Leer `cmd/monitor/main.go` (punto de entrada)
3. ‚úÖ Estudiar arquitectura modular en `pkg/monitor/`
   - `monitor.go` ‚Üí Orquestador principal
   - `models.go` ‚Üí Estructuras de datos
   - `config.go` ‚Üí Configuraci√≥n
   - `fetcher.go` ‚Üí Cliente API
   - `snapshot.go` ‚Üí Creaci√≥n de snapshots
   - `changes.go` ‚Üí Detecci√≥n de cambios
   - `persistence.go` ‚Üí Guardado de datos
   - `exporter.go` ‚Üí Exportaci√≥n CSV
   - `display.go` ‚Üí Visualizaci√≥n
4. ‚úÖ Analizar `pkg/scraper/chart_scraper.go` (scraping)
5. ‚úÖ Revisar modelos de datos
6. ‚úÖ Ejecutar y observar outputs
7. ‚úÖ Modificar configuraciones
8. ‚úÖ Agregar features propios


## üìñ Gu√≠a de Uso y Workflows

### Escenario 1: Primera Ejecuci√≥n del Sistema

**Objetivo:** Iniciar monitoreo desde cero

**Pasos:**
```bash
# 1. Clonar/descargar proyecto
cd MonitoreoDanich

# 2. Configurar config.yaml
nano config.yaml
# Verificar: URL, sorters, l√≠neas corresponden al packing

# 3. Compilar monitor (arquitectura modular)
go build -o bin/monitor.exe cmd/monitor/main.go

# Opcional: Compilar herramientas adicionales
go build -o bin/infer-decisions.exe cmd/infer-decisions/main.go
go build -o bin/capture-charts.exe cmd/capture-charts/main.go

# 4. Probar conectividad (opcional)
curl http://192.168.121.2/api/api/assignments_list

# 5. Iniciar monitor
./bin/monitor.exe
```

**Output esperado:**
- Captura cada 30 segundos
- Muestra distribuci√≥n de sorters
- Exporta a CSV continuamente
- Detecta y registra cambios

**Dejar corriendo:** 1-2 semanas para obtener datos suficientes (>100 cambios).

---

### Escenario 2: Usar Advisor con Ollama (Prompting)

**Objetivo:** Obtener recomendaciones en tiempo real sin datos hist√≥ricos

**Pre-requisitos:**
```bash
# 1. Instalar Ollama
winget install Ollama.Ollama

# 2. Descargar modelo
ollama pull phi3:mini
# o para m√°s potencia:
ollama pull llama3.2:3b

# 3. Iniciar servidor Ollama
ollama serve
# Escucha en http://localhost:11434
```

**Uso manual desde Go:**
```go
// En un script de testing
import "danich/pkg/advisor"

snapshot := advisor.DataSnapshot{
    Assignments: assignments,
    ChartData:   chartData,
}

advice, err := advisor.GetAdvice(snapshot)
if err != nil {
    log.Fatal(err)
}

fmt.Printf("Acci√≥n: %s\n", advice.Accion)
fmt.Printf("SKU: %s\n", advice.SKU)
fmt.Printf("De Sorter %d a Sorter %d\n", advice.DeSorter, advice.ASorter)
fmt.Printf("L√≠neas sugeridas: %s\n", advice.LineasSugeridas)
fmt.Printf("Raz√≥n: %s\n", advice.Razon)
fmt.Printf("Balance esperado: %s\n", advice.BalanceEsperado)
```

**Ventaja:** Funciona inmediatamente sin necesidad de datos hist√≥ricos.

---

### Escenario 3: Entrenar Modelo ML (Fine-tuning)

**Objetivo:** Crear modelo predictivo basado en decisiones hist√≥ricas

**Pre-requisitos:**
- Monitor corriendo al menos 1-2 semanas
- Al menos 50 cambios detectados (ideal: >100)

**Pasos:**
```bash
# 1. Verificar cambios recolectados
cat training_data/changes_log.json | grep "change_type" | wc -l
# Si <50, esperar m√°s tiempo

# 2. Generar decisiones inferidas
./bin/infer-decisions.exe

# Verifica output:
# - decisiones_inferidas.json (detalle)
# - decisiones_training.csv (para ML)

# 3. Configurar Python
python -m venv venv
source venv/Scripts/activate
pip install pandas scikit-learn xgboost joblib

# 4. Entrenar modelo
python train_model.py

# Verifica output:
# - decision_model.pkl (modelo entrenado)
# - label_encoder.pkl (encoder de clases)
# - training_metrics.json (m√©tricas)
```

**Resultado esperado:**
- Con 50-100 muestras: accuracy ~60-70% (b√°sico)
- Con 100-200 muestras: accuracy ~75-85% (bueno)
- Con >200 muestras: accuracy >85% (excelente)

**Si accuracy es baja (<60%):**
- Seguir recolectando datos
- Volver a entrenar en 1-2 semanas m√°s

---

### Escenario 4: Analizar Calidad de Datos

**Objetivo:** Verificar que los datos recolectados son correctos

**Validar CSV:**
```bash
# 1. Ver √∫ltimas l√≠neas del CSV
tail -n 20 training_data/training_data.csv

# 2. Contar registros por sorter
grep ";1;" training_data/training_data.csv | wc -l  # Sorter 1
grep ";2;" training_data/training_data.csv | wc -l  # Sorter 2

# 3. Ver distribuci√≥n de calibres
cut -d';' -f4 training_data/training_data.csv | sort | uniq -c

# 4. Validar porcentajes (no deben ser 0)
awk -F';' '$8 == 0 {print}' training_data/training_data.csv
# Si hay muchos con porcentaje 0, hay problema con scraping
```

**Validar JSON:**
```bash
# Ver √∫ltimo snapshot
cat training_data/current_snapshot.json | jq '.chart_data'

# Verificar que ambos sorters tienen datos
cat training_data/current_snapshot.json | jq '.chart_data | keys'
# Esperado: ["1", "2"]
```

---

### Escenario 5: Migrar a Otro Packing

**Objetivo:** Usar el sistema en un packing diferente

**Pasos:**
```bash
# 1. Copiar binarios al nuevo servidor
scp bin/monitor.exe user@new-packing:/path/to/app/

# 2. Crear nuevo config.yaml
cat > config.yaml << EOF
packing:
  name: "Packing XYZ"
  url: "http://10.0.0.50"
  sorters: 3
  lineas: 12
  fruta: "arandano"

monitor:
  intervalo_segundos: 30
  capture_charts: true

data:
  folder: "training_data_xyz"
EOF

# 3. Crear carpeta de datos
mkdir training_data_xyz

# 4. Ejecutar monitor
./monitor.exe
```

**Sin recompilar c√≥digo** - Todo se adapta del YAML.

---

### Escenario 6: Debugging - Captura No Funciona

**Problema:** El monitor corre pero no captura porcentajes

**Diagn√≥stico:**
```bash
# 1. Probar captura aislada
./bin/capture-charts.exe

# Si falla, verificar:
# - ¬øChrome est√° instalado?
# - ¬øLa URL es correcta en config.yaml?
# - ¬øEl selector CSS cambi√≥ en la web?
```

**Verificar selector CSS:**
```bash
# Inspeccionar HTML de la p√°gina
curl http://192.168.121.2/assignment/1 > page.html
cat page.html | grep "percentage"

# Si el selector cambi√≥, editar:
# pkg/scraper/chart_scraper.go
# Buscar: div.relative.w-full.flex.justify-between.items-center
# Actualizar con nuevo selector
```

**Verificar JavaScript:**
```go
// En chart_scraper.go, agregar logs
chromedp.Run(ctx,
    chromedp.Navigate(url),
    chromedp.Sleep(3*time.Second),
    chromedp.Evaluate(`console.log("DOM loaded")`, nil),
    // ... resto del c√≥digo
)
```

---

### Escenario 7: Monitoreo 24/7 en Producci√≥n

**Objetivo:** Ejecutar monitor como servicio continuo

**Opci√≥n 1: Screen (Linux)**
```bash
screen -S monitor
./bin/monitor
# Presionar Ctrl+A, luego D para detach
# Reconectar: screen -r monitor
```

**Opci√≥n 2: systemd (Linux)**
```ini
# /etc/systemd/system/danich-monitor.service
[Unit]
Description=Danich Sorter Monitor
After=network.target

[Service]
Type=simple
User=monitor
WorkingDirectory=/opt/danich
ExecStart=/opt/danich/bin/monitor
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl enable danich-monitor
sudo systemctl start danich-monitor
sudo systemctl status danich-monitor
```

**Opci√≥n 3: Tarea programada (Windows)**
```
1. Abrir Task Scheduler
2. Create Basic Task
   - Name: Danich Monitor
   - Trigger: At startup
   - Action: Start a program
   - Program: C:\danich\bin\monitor.exe
   - Start in: C:\danich
3. Properties > Settings
   - [x] If task fails, restart every 1 minute
```

---

## üåê Escalabilidad y Filosof√≠a

### Dise√±o Multi-Packing

El sistema est√° dise√±ado con la filosof√≠a de **"un packing a la vez"** pero con **m√°xima flexibilidad**:

**Principios:**
1. **Cada packing tiene su propio servidor:** Diferentes URLs, redes locales
2. **Configuraci√≥n independiente:** Cada packing define sorters, l√≠neas, fruta
3. **Cambio r√°pido:** Solo editar YAML y reiniciar (no recompilar)
4. **Sin c√≥digo hardcoded:** Todo configurable externamente

**¬øPor qu√© un packing a la vez?**
- Simplicidad operacional
- Enfoque claro en un contexto
- Facilita debugging y an√°lisis
- Los packings suelen estar en redes diferentes

**Adaptaci√≥n a nuevos packings:**
```yaml
# Ejemplo: Packing en otra planta
packing:
  name: "Packing ABC"
  url: "http://10.0.0.50"    # Diferente servidor
  sorters: 3                  # M√°s sorters
  lineas: 12                  # M√°s l√≠neas
  fruta: "arandano"           # Diferente fruta
```

El sistema se adapta autom√°ticamente sin modificar c√≥digo.

**Archivos clave para portabilidad:**
- `config.yaml`: Configuraci√≥n activa
- `config.example.yaml`: Ejemplos de diferentes packings
- Los binarios compilados (`bin/monitor.exe`) son portables

---

## üìù Resumen Ejecutivo

### ¬øQu√© hace este sistema?

MonitoreoDanich es una **plataforma completa de inteligencia artificial** para optimizaci√≥n de sorters de fruta que:

1. **Monitorea continuamente** (cada 30s) el estado de sorters
2. **Recolecta porcentajes reales** desde gr√°ficos HTML/JavaScript
3. **Infiere decisiones autom√°ticamente** sin etiquetado manual
4. **Asesora con IA** mediante dos estrategias:
   - **Prompting (Ollama):** Funciona desde el d√≠a 1
   - **Fine-tuning (XGBoost):** Aprende de datos hist√≥ricos

### Tecnolog√≠as Clave

- **Go 1.25.4:** Monitoreo, scraping, inferencia
- **Python 3.11:** Machine learning (XGBoost)
- **chromedp:** Scraping de JavaScript
- **Ollama:** LLM local para prompting
- **XGBoost:** Clasificaci√≥n de decisiones

### Componentes Principales

| Componente | Archivo | Funci√≥n |
|------------|---------|---------|
| Monitor | `cmd/monitor/main.go` | Loop continuo de recolecci√≥n |
| Core Modular | `pkg/monitor/*.go` | 9 archivos especializados (modularizado) |
| Advisor | `pkg/advisor/advisor.go` | Prompting con Ollama |
| Inferencia | `pkg/advisor/decision_inference.go` | Etiquetado autom√°tico |
| Entrenamiento | `train_model.py` | Fine-tuning XGBoost |

### Datos Generados

| Archivo | Contenido | Uso |
|---------|-----------|-----|
| `dataset.json` | Snapshots hist√≥ricos | An√°lisis retrospectivo |
| `changes_log.json` | Cambios detectados | Input para inferencia |
| `training_data.csv` | Porcentajes + features | Dataset base ML |
| `decisiones_inferidas.json` | Decisiones con raz√≥n | Detalle completo |
| `decisiones_training.csv` | Dataset etiquetado | Input para XGBoost |
| `decision_model.pkl` | Modelo entrenado | Predicci√≥n de razones |

### Estado Actual

**‚úÖ Implementado:**
- ‚úÖ Monitoreo continuo funcionando
- ‚úÖ Scraping de gr√°ficos con chromedp
- ‚úÖ Detecci√≥n de cambios
- ‚úÖ Exportaci√≥n a CSV y JSON
- ‚úÖ **Arquitectura modular (9 archivos especializados)**
- ‚úÖ Advisor con Ollama (no integrado en loop)
- ‚úÖ Sistema de inferencia autom√°tica
- ‚úÖ Script de entrenamiento ML

**‚ö†Ô∏è En progreso:**
- Recolecci√≥n de datos (necesita >100 cambios para ML confiable)
- Entrenamiento del modelo (accuracy mejorar√° con m√°s datos)

**üîú Pr√≥ximos pasos:**
1. Dejar monitor corriendo 1-2 semanas m√°s
2. Re-ejecutar `infer-decisions` con m√°s cambios
3. Re-entrenar modelo con >100 muestras
4. Integrar predicciones en monitor
5. Integrar asesoramiento Ollama en loop

### Documentos Relacionados

- **DOCUMENTACION_TECNICA.md** (este archivo): Arquitectura completa y detalles t√©cnicos
- **FLUJO_DATOS.md**: Flujo detallado paso a paso desde API hasta CSV
- **README.md**: Gu√≠a r√°pida de instalaci√≥n y uso
- **todo.md**: TODOs y mejoras futuras
- **config.yaml**: Configuraci√≥n activa del sistema

---

**Proyecto:** MonitoreoDanich  
**Versi√≥n:** 2.0  
**Autor:** Sistema de Monitoreo y Advisor de Sorters  
**√öltima actualizaci√≥n:** 27 Noviembre 2025  
**Lenguajes:** Go 1.25.4 + Python 3.11  
**Licencia:** Uso interno - Danich Packing
